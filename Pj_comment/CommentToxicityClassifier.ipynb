{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span><ul class=\"toc-item\"><li><span><a href=\"#Логистическая-регрессия\" data-toc-modified-id=\"Логистическая-регрессия-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Логистическая регрессия</a></span></li><li><span><a href=\"#Дерево-решений\" data-toc-modified-id=\"Дерево-решений-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Дерево решений</a></span></li><li><span><a href=\"#Случайный-лес\" data-toc-modified-id=\"Случайный-лес-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Случайный лес</a></span></li><li><span><a href=\"#CatBoost\" data-toc-modified-id=\"CatBoost-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>CatBoost</a></span></li><li><span><a href=\"#LGBM_Boost\" data-toc-modified-id=\"LGBM_Boost-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>LGBM_Boost</a></span></li><li><span><a href=\"#Тестирование\" data-toc-modified-id=\"Тестирование-2.6\"><span class=\"toc-item-num\">2.6&nbsp;&nbsp;</span>Тестирование</a></span></li></ul></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Выводы</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. Чтобы это осуществить, неоходимо разработать модель машинного обучения, которая будет классифицировать пользовательские комментарии на позитивные и негативные."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import transformers\n",
    "import re\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from tqdm import notebook\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    make_scorer,\n",
    "    precision_score, \n",
    "    recall_score, \n",
    "    f1_score)\n",
    "\n",
    "from sklearn.model_selection import (\n",
    "    cross_val_score,\n",
    "    train_test_split,\n",
    "    RandomizedSearchCV)\n",
    "\n",
    "from nltk.corpus import wordnet\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  toxic\n",
       "0           0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1           1  D'aww! He matches this background colour I'm s...      0\n",
       "2           2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3           3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4           4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comm = pd.read_csv('/datasets/toxic_comments.csv')\n",
    "\n",
    "df_comm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159292 entries, 0 to 159291\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   Unnamed: 0  159292 non-null  int64 \n",
      " 1   text        159292 non-null  object\n",
      " 2   toxic       159292 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df_comm.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество пропусков:  Unnamed: 0    0\n",
      "text          0\n",
      "toxic         0\n",
      "dtype: int64\n",
      "\n",
      "Количество дубликатов  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Количество пропусков: ',df_comm.isna().sum())\n",
    "print('')\n",
    "print('Количество дубликатов ',df_comm.duplicated().sum())\n",
    "df_comm.value_counts('toxic').plot(kind = 'pie', figsize = (5,5), title = 'Количество токсичных комментариев',\n",
    "                                   ylabel = '', legend = True, autopct='%1.0f%%')\n",
    "plt.legend(['no toxic', 'toxic'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Представлен набор данных с разметкой о токсичности правок. Общее число наблюдений 159292, 3 столбца с признаками: unnamed, text и toxic. Последний является целевым признаком. Unnamed, вероятно, содержит порядковое число, однако последние значения в нем не совпадают с индексом.Toxic содержит нативный текст (без предобработки). Пропуски и явные дубликаты не обнаружены. Классы несбалансированны: 0 -90%, 1 - 10%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([     0,   6084,   6609,   6859,   7209,   8787,  11671,  12525,\n",
       "        14127,  15449,  18206,  18351,  19486,  24376,  25194,  25928,\n",
       "        26494,  26846,  29375,  29912,  34766,  35577,  37375,  38792,\n",
       "        38998,  43420,  43655,  45863,  46208,  50362,  51340,  53126,\n",
       "        57485,  57895,  58402,  60493,  67129,  69570,  70507,  72220,\n",
       "        73493,  74173,  74725,  82241,  83122,  84321,  88828,  89456,\n",
       "        89865,  90079,  92463,  96416,  97400,  98139,  98523,  99685,\n",
       "       112479, 114753, 118012, 119123, 122593, 123102, 123490, 123861,\n",
       "       125798, 127403, 129312, 129913, 132571, 133024, 137547, 138276,\n",
       "       138938, 141579, 142714, 143829, 144528, 151819, 155558, 156165])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comm.loc[df_comm['Unnamed: 0'].diff() != 1, 'Unnamed: 0'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вероятно, что часть наблюдений была удалена, старые индексы сохранили в столбце Unnamed: 0. Задача сохранить этот столбец не стоит, поэтому далее его удалим. Однако стоит уточнить, почему от части данных решили избавиться. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comm_new = df_comm.drop('Unnamed: 0', axis = 1)\n",
    "\n",
    "df_comm_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text\n",
      "0  The striped bats are hanging on their feet for...\n",
      "1      you should be ashamed of yourself went worked\n",
      "0    the strip bat be hang on their foot for best\n",
      "1       you should be ashamed of yourself go work\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    text = text.lower()\n",
    "    lemm_text = \" \".join(lemmatizer.lemmatize(w, get_wordnet_pos(lemmatizer.lemmatize(w))) for w in nltk.word_tokenize(text))\n",
    "    cleared_text = re.sub(r'[^a-zA-Z]', ' ', lemm_text) \n",
    "    return \" \".join(cleared_text.split())\n",
    "\n",
    "\n",
    "sentence1 = \"The striped bats are hanging on their feet for best\"\n",
    "sentence2 = \"you should be ashamed of yourself went worked\"\n",
    "df_my = pd.DataFrame([sentence1, sentence2], columns = ['text'])\n",
    "print(df_my)\n",
    "\n",
    "print(df_my['text'].apply(lemmatize_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 159292/159292 [20:53<00:00, 127.03it/s]\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "df_comm_new['lemm_text'] = df_comm_new['text'].progress_apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>lemm_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation why the edits make under my userna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>d aww he match this background colour i m seem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man i m really not try to edit war it s ju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>more i ca n t make any real suggestion on impr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>you sir be my hero any chance you remember wha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159287</th>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "      <td>0</td>\n",
       "      <td>and for the second time of ask when your view ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159288</th>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "      <td>0</td>\n",
       "      <td>you should be ashamed of yourself that be a ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159289</th>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
       "      <td>0</td>\n",
       "      <td>spitzer umm theres no actual article for prost...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159290</th>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "      <td>and it look like it wa actually you who put on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159291</th>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "      <td>0</td>\n",
       "      <td>and i really do n t think you understand i com...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159292 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic  \\\n",
       "0       Explanation\\nWhy the edits made under my usern...      0   \n",
       "1       D'aww! He matches this background colour I'm s...      0   \n",
       "2       Hey man, I'm really not trying to edit war. It...      0   \n",
       "3       \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4       You, sir, are my hero. Any chance you remember...      0   \n",
       "...                                                   ...    ...   \n",
       "159287  \":::::And for the second time of asking, when ...      0   \n",
       "159288  You should be ashamed of yourself \\n\\nThat is ...      0   \n",
       "159289  Spitzer \\n\\nUmm, theres no actual article for ...      0   \n",
       "159290  And it looks like it was actually you who put ...      0   \n",
       "159291  \"\\nAnd ... I really don't think you understand...      0   \n",
       "\n",
       "                                                lemm_text  \n",
       "0       explanation why the edits make under my userna...  \n",
       "1       d aww he match this background colour i m seem...  \n",
       "2       hey man i m really not try to edit war it s ju...  \n",
       "3       more i ca n t make any real suggestion on impr...  \n",
       "4       you sir be my hero any chance you remember wha...  \n",
       "...                                                   ...  \n",
       "159287  and for the second time of ask when your view ...  \n",
       "159288  you should be ashamed of yourself that be a ho...  \n",
       "159289  spitzer umm theres no actual article for prost...  \n",
       "159290  and it look like it wa actually you who put on...  \n",
       "159291  and i really do n t think you understand i com...  \n",
       "\n",
       "[159292 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comm_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>lemm_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>explanation why the edits make under my userna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>d aww he match this background colour i m seem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>hey man i m really not try to edit war it s ju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>more i ca n t make any real suggestion on impr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>you sir be my hero any chance you remember wha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   toxic                                          lemm_text\n",
       "0      0  explanation why the edits make under my userna...\n",
       "1      0  d aww he match this background colour i m seem...\n",
       "2      0  hey man i m really not try to edit war it s ju...\n",
       "3      0  more i ca n t make any real suggestion on impr...\n",
       "4      0  you sir be my hero any chance you remember wha..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comm_new = df_comm_new.drop(['text'], axis=1)\n",
    "\n",
    "df_comm_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df_comm_new['toxic']\n",
    "features = df_comm_new.drop(['toxic'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemm_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>97400</th>\n",
       "      <td>bushranger you re a grass with no sense of hum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4383</th>\n",
       "      <td>need administrative help i have be block iniqu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103680</th>\n",
       "      <td>i d also like to point out that he ha use a th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38573</th>\n",
       "      <td>you cant block me you fuck retard brb nigger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128311</th>\n",
       "      <td>i believe that the frequency of the wave need ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109993</th>\n",
       "      <td>hahaha i dont live in a lie like you and dont ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85412</th>\n",
       "      <td>march march</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133249</th>\n",
       "      <td>agree we really should try to stick to the sub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130333</th>\n",
       "      <td>umm killer do you not like that he copy your w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77285</th>\n",
       "      <td>bradford city i be remove unreferanced content</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127433 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                lemm_text\n",
       "97400   bushranger you re a grass with no sense of hum...\n",
       "4383    need administrative help i have be block iniqu...\n",
       "103680  i d also like to point out that he ha use a th...\n",
       "38573        you cant block me you fuck retard brb nigger\n",
       "128311  i believe that the frequency of the wave need ...\n",
       "...                                                   ...\n",
       "109993  hahaha i dont live in a lie like you and dont ...\n",
       "85412                                         march march\n",
       "133249  agree we really should try to stick to the sub...\n",
       "130333  umm killer do you not like that he copy your w...\n",
       "77285      bradford city i be remove unreferanced content\n",
       "\n",
       "[127433 rows x 1 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size = 0.2, random_state = 12345)\n",
    "\n",
    "features_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(127433, 136833)\n",
      "(31859, 136833)\n"
     ]
    }
   ],
   "source": [
    "# Загрузка стоп-слов\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "count_tf_idf = TfidfVectorizer(stop_words=stop_words)\n",
    "\n",
    "\n",
    "features_train = pd.DataFrame(features_train)\n",
    "features_test = pd.DataFrame(features_test)\n",
    "\n",
    "features_train = count_tf_idf.fit_transform(features_train['lemm_text'])\n",
    "features_test = count_tf_idf.transform(features_test['lemm_text'])\n",
    "\n",
    "\n",
    "print(features_train.shape)\n",
    "print(features_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод**\n",
    "\n",
    "Был представлен набор данных с разметкой о токсичности правок. Общее число наблюдений 159292, 3 столбца с признаками: unnamed, text и toxic. Последний являлся целевым признаком. Unnamed, вероятно, содержал порядковое число, однако последние значения в нем не совпадали с индексом. Toxic содержал нативный текст (без предобработки). Пропуски и явные дубликаты не были обнаружены. Классы были несбалансированны: 0 -90%, 1 - 10%.\n",
    "\n",
    "Вероятно, что часть наблюдений в столбце Unnamed была удалена, старые индексы сохранили в столбце Unnamed: 0. Задача сохранить этот столбец не стояла, поэтому далее его удалили. Однако, в дальнейшем, стоит уточнить, почему от части данных решили избавиться. Были созданы несколько выборок: обучающая и тестовая.\n",
    "\n",
    "Была выполнена векторизация текстов, для определения тональности были применены величины TF-IDF как признаки.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model Hyperparameters: {'penalty': 'l1', 'C': 5}\n",
      "F1 на CV: 0.7591217971309911\n"
     ]
    }
   ],
   "source": [
    "best_f1 = 0\n",
    "best_params = {}\n",
    "best_model_log = None\n",
    "scores = []\n",
    "\n",
    "for pen in ['l1', 'l2']:\n",
    "    for c in range (5,15):\n",
    "        model = LogisticRegression(max_iter=1000, penalty=pen, C=c, solver='liblinear')\n",
    "        scoring = make_scorer(f1_score)\n",
    "        scores = cross_val_score(model, features_train,target_train, cv = 2, scoring=scoring)\n",
    "        final_score = abs(np.mean(scores))\n",
    "        if final_score > best_f1:\n",
    "            best_f1 = final_score\n",
    "            best_params = {'penalty': pen, 'C': c}\n",
    "            best_model_log = model\n",
    "\n",
    "print('Best Model Hyperparameters:', best_params)\n",
    "print('F1 на CV:', best_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model Hyperparameters: {'penalty': 'l2', 'C': 7}\n",
      "F1 на CV: 0.7539933595472352\n"
     ]
    }
   ],
   "source": [
    "# добавим взвешивание классов\n",
    "\n",
    "best_f1 = 0\n",
    "best_params = {}\n",
    "best_model_log_balanced = None\n",
    "scores = []\n",
    "\n",
    "for pen in ['l1', 'l2']:\n",
    "    for c in range (5,15):\n",
    "        model = LogisticRegression(max_iter=1000, penalty=pen, C=c, solver='liblinear', class_weight = 'balanced')\n",
    "        scoring = make_scorer(f1_score)\n",
    "        scores = cross_val_score(model, features_train,target_train, cv = 2, scoring=scoring)\n",
    "        final_score = abs(np.mean(scores))\n",
    "        if final_score > best_f1:\n",
    "            best_f1 = final_score\n",
    "            best_params = {'penalty': pen, 'C': c}\n",
    "            best_model_log = model\n",
    "\n",
    "print('Best Model Hyperparameters:', best_params)\n",
    "print('F1 на CV:', best_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1 для модели логистической регрессии (без взвешивания классов) для кросс-валидационной выборки - 0.7591217971309911."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Дерево решений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 на CV: 0.6003711496390347 и максимальную глубину: 10\n"
     ]
    }
   ],
   "source": [
    "best_model_tree = None\n",
    "best_result = 0\n",
    "max_depth = None\n",
    "scores = []\n",
    "\n",
    "for depth in range(1,11,1):\n",
    "    model = DecisionTreeClassifier(max_depth = depth, random_state = 12345)\n",
    "    scoring = make_scorer(f1_score)\n",
    "    scores = cross_val_score(model, features_train,target_train, cv = 2, scoring=scoring)\n",
    "    final_score = abs(np.mean(scores))       \n",
    "    if final_score > best_result:\n",
    "        best_result = final_score\n",
    "        best_model_tree = model\n",
    "        max_depth = depth        \n",
    "\n",
    "print(\"F1 на CV:\", best_result, 'и максимальную глубину:', max_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 на CV: 0.5668563918194784 и максимальную глубину: 10\n"
     ]
    }
   ],
   "source": [
    "# добавим взвешивание классов\n",
    "\n",
    "best_model_tree_balanced = None\n",
    "best_result = 0\n",
    "max_depth = None\n",
    "scores = []\n",
    "\n",
    "for depth in range(1,11,1):\n",
    "    model = DecisionTreeClassifier(max_depth = depth, random_state = 12345, class_weight = 'balanced')\n",
    "    scoring = make_scorer(f1_score)\n",
    "    scores = cross_val_score(model, features_train,target_train, cv = 2, scoring=scoring)\n",
    "    final_score = abs(np.mean(scores))       \n",
    "    if final_score > best_result:\n",
    "        best_result = final_score\n",
    "        best_model_tree_balanced = model\n",
    "        max_depth = depth        \n",
    "\n",
    "print(\"F1 на CV:\", best_result, 'и максимальную глубину:', max_depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1 для дерева решений (без взвешивания классов) для кросс-валидационной выборки - 0.6003711496390347."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Случайный лес"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 на CV: 0.5668563918194784 , число деревьев: 20  и максимальную глубину: 10\n"
     ]
    }
   ],
   "source": [
    "best_model_forest = None\n",
    "best_result = 0\n",
    "max_depth = None\n",
    "n_estimators = None\n",
    "scores = []            \n",
    "               \n",
    "for est in range(20,41,20):\n",
    "    for depth in range(1,11,1):\n",
    "        model = DecisionTreeClassifier(max_depth = depth, random_state = 12345, class_weight = 'balanced')\n",
    "        scoring = make_scorer(f1_score)\n",
    "        scores = cross_val_score(model, features_train,target_train, cv = 2, scoring=scoring)\n",
    "        final_score = abs(np.mean(scores))       \n",
    "        if final_score > best_result:\n",
    "            best_result = final_score\n",
    "            best_model_forest = model\n",
    "            max_depth = depth\n",
    "            n_estimators = est\n",
    "            \n",
    "print(\"F1 на CV:\", best_result,',','число деревьев:', n_estimators,' и максимальную глубину:', max_depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1 для случайного леса для кросс-валидационной выборки - 0.5668563918194784."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.21649\n",
      "0:\tlearn: 0.4990019\ttotal: 1.58s\tremaining: 6m 33s\n",
      "100:\tlearn: 0.1383931\ttotal: 1m 47s\tremaining: 2m 39s\n",
      "200:\tlearn: 0.1169059\ttotal: 3m 35s\tremaining: 52.4s\n",
      "249:\tlearn: 0.1098941\ttotal: 4m 27s\tremaining: 0us\n",
      "Learning rate set to 0.216491\n",
      "0:\tlearn: 0.4962071\ttotal: 1.55s\tremaining: 6m 25s\n",
      "100:\tlearn: 0.1393009\ttotal: 1m 49s\tremaining: 2m 41s\n",
      "200:\tlearn: 0.1169520\ttotal: 3m 36s\tremaining: 52.7s\n",
      "249:\tlearn: 0.1101894\ttotal: 4m 28s\tremaining: 0us\n",
      "F1 на CV 0.7263386773408648\n"
     ]
    }
   ],
   "source": [
    "model_cat = CatBoostClassifier(iterations=250, random_state=12345, verbose= 100)\n",
    "\n",
    "train_f1 = cross_val_score(model_cat, \n",
    "                       features_train, \n",
    "                       target_train, \n",
    "                       cv=2, \n",
    "                       scoring='f1').mean()\n",
    "\n",
    "print('F1 на CV', train_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1 для CatBoost для кросс-валидационной выборки - 0.7263386773408648."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBM_Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_search.py:285: UserWarning: The total space of parameters 9 is smaller than n_iter=10. Running 9 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 6478, number of negative: 57238\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.996392\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.996392\n",
      "[LightGBM] [Debug] init for col-wise cost 5.496663 seconds, init for row-wise cost 5.532479 seconds\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 5.808797 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 330546\n",
      "[LightGBM] [Info] Number of data points in the train set: 63716, number of used features: 6556\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101670 -> initscore=-2.178806\n",
      "[LightGBM] [Info] Start training from score -2.178806\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Info] Number of positive: 6478, number of negative: 57239\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.996379\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.996379\n",
      "[LightGBM] [Debug] init for col-wise cost 5.532238 seconds, init for row-wise cost 5.663115 seconds\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 5.876450 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 330609\n",
      "[LightGBM] [Info] Number of data points in the train set: 63717, number of used features: 6549\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101668 -> initscore=-2.178824\n",
      "[LightGBM] [Info] Start training from score -2.178824\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Info] Number of positive: 6478, number of negative: 57238\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.996392\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.996392\n",
      "[LightGBM] [Debug] init for col-wise cost 5.528062 seconds, init for row-wise cost 5.505937 seconds\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 5.813559 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Debug] Using Sparse Multi-Val Bin\n",
      "[LightGBM] [Info] Total Bins 330546\n",
      "[LightGBM] [Info] Number of data points in the train set: 63716, number of used features: 6556\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101670 -> initscore=-2.178806\n",
      "[LightGBM] [Info] Start training from score -2.178806\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Info] Number of positive: 6478, number of negative: 57239\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.996379\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.996379\n",
      "[LightGBM] [Debug] init for col-wise cost 5.500513 seconds, init for row-wise cost 5.699034 seconds\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 5.898565 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 330609\n",
      "[LightGBM] [Info] Number of data points in the train set: 63717, number of used features: 6549\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101668 -> initscore=-2.178824\n",
      "[LightGBM] [Info] Start training from score -2.178824\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Info] Number of positive: 6478, number of negative: 57238\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.996392\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.996392\n",
      "[LightGBM] [Debug] init for col-wise cost 5.512168 seconds, init for row-wise cost 5.721592 seconds\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 5.902103 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 330546\n",
      "[LightGBM] [Info] Number of data points in the train set: 63716, number of used features: 6556\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101670 -> initscore=-2.178806\n",
      "[LightGBM] [Info] Start training from score -2.178806\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Info] Number of positive: 6478, number of negative: 57239\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.996379\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.996379\n",
      "[LightGBM] [Debug] init for col-wise cost 5.843319 seconds, init for row-wise cost 6.154176 seconds\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 6.558035 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 330609\n",
      "[LightGBM] [Info] Number of data points in the train set: 63717, number of used features: 6549\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101668 -> initscore=-2.178824\n",
      "[LightGBM] [Info] Start training from score -2.178824\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Info] Number of positive: 6478, number of negative: 57238\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.996392\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.996392\n",
      "[LightGBM] [Debug] init for col-wise cost 5.687189 seconds, init for row-wise cost 5.623879 seconds\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 5.882617 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Debug] Using Sparse Multi-Val Bin\n",
      "[LightGBM] [Info] Total Bins 330546\n",
      "[LightGBM] [Info] Number of data points in the train set: 63716, number of used features: 6556\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101670 -> initscore=-2.178806\n",
      "[LightGBM] [Info] Start training from score -2.178806\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 16 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 16 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Info] Number of positive: 6478, number of negative: 57239\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.996379\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.996379\n",
      "[LightGBM] [Debug] init for col-wise cost 5.802100 seconds, init for row-wise cost 5.693117 seconds\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 5.914256 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 330609\n",
      "[LightGBM] [Info] Number of data points in the train set: 63717, number of used features: 6549\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101668 -> initscore=-2.178824\n",
      "[LightGBM] [Info] Start training from score -2.178824\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Info] Number of positive: 6478, number of negative: 57238\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.996392\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.996392\n",
      "[LightGBM] [Debug] init for col-wise cost 5.802287 seconds, init for row-wise cost 5.489071 seconds\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 5.705420 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 330546\n",
      "[LightGBM] [Info] Number of data points in the train set: 63716, number of used features: 6556\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101670 -> initscore=-2.178806\n",
      "[LightGBM] [Info] Start training from score -2.178806\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 16 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 16 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Info] Number of positive: 6478, number of negative: 57239\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.996379\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.996379\n",
      "[LightGBM] [Debug] init for col-wise cost 5.912454 seconds, init for row-wise cost 5.716915 seconds\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 5.904483 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 330609\n",
      "[LightGBM] [Info] Number of data points in the train set: 63717, number of used features: 6549\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101668 -> initscore=-2.178824\n",
      "[LightGBM] [Info] Start training from score -2.178824\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Info] Number of positive: 6478, number of negative: 57238\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.996392\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.996392\n",
      "[LightGBM] [Debug] init for col-wise cost 5.497980 seconds, init for row-wise cost 5.539622 seconds\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 5.759172 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Debug] Using Sparse Multi-Val Bin\n",
      "[LightGBM] [Info] Total Bins 330546\n",
      "[LightGBM] [Info] Number of data points in the train set: 63716, number of used features: 6556\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101670 -> initscore=-2.178806\n",
      "[LightGBM] [Info] Start training from score -2.178806\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 16 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 16 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Info] Number of positive: 6478, number of negative: 57239\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.996379\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.996379\n",
      "[LightGBM] [Debug] init for col-wise cost 5.704800 seconds, init for row-wise cost 5.484606 seconds\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 5.783754 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 330609\n",
      "[LightGBM] [Info] Number of data points in the train set: 63717, number of used features: 6549\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101668 -> initscore=-2.178824\n",
      "[LightGBM] [Info] Start training from score -2.178824\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 6478, number of negative: 57238\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.996392\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.996392\n",
      "[LightGBM] [Debug] init for col-wise cost 5.401143 seconds, init for row-wise cost 6.397237 seconds\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 6.603224 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 330546\n",
      "[LightGBM] [Info] Number of data points in the train set: 63716, number of used features: 6556\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101670 -> initscore=-2.178806\n",
      "[LightGBM] [Info] Start training from score -2.178806\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 6478, number of negative: 57239\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.996379\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.996379\n",
      "[LightGBM] [Debug] init for col-wise cost 5.632672 seconds, init for row-wise cost 5.560009 seconds\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 5.853192 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 330609\n",
      "[LightGBM] [Info] Number of data points in the train set: 63717, number of used features: 6549\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101668 -> initscore=-2.178824\n",
      "[LightGBM] [Info] Start training from score -2.178824\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 6478, number of negative: 57238\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.996392\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.996392\n",
      "[LightGBM] [Debug] init for col-wise cost 5.701101 seconds, init for row-wise cost 5.496054 seconds\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 5.713900 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 330546\n",
      "[LightGBM] [Info] Number of data points in the train set: 63716, number of used features: 6556\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101670 -> initscore=-2.178806\n",
      "[LightGBM] [Info] Start training from score -2.178806\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 29 and depth = 7\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 29 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 26 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 27 and depth = 7\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 29 and depth = 7\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 26 and depth = 7\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 6478, number of negative: 57239\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.996379\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.996379\n",
      "[LightGBM] [Debug] init for col-wise cost 6.092802 seconds, init for row-wise cost 5.495054 seconds\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 5.702830 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 330609\n",
      "[LightGBM] [Info] Number of data points in the train set: 63717, number of used features: 6549\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101668 -> initscore=-2.178824\n",
      "[LightGBM] [Info] Start training from score -2.178824\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 30 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 24 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 30 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 29 and depth = 7\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 22 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 6478, number of negative: 57238\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.996392\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.996392\n",
      "[LightGBM] [Debug] init for col-wise cost 5.798526 seconds, init for row-wise cost 52.288389 seconds\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 52.695505 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 330546\n",
      "[LightGBM] [Info] Number of data points in the train set: 63716, number of used features: 6556\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101670 -> initscore=-2.178806\n",
      "[LightGBM] [Info] Start training from score -2.178806\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 29 and depth = 7\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 29 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 26 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 27 and depth = 7\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 29 and depth = 7\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 26 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 28 and depth = 7\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 30 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 28 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 29 and depth = 7\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 18 and depth = 7\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 29 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 24 and depth = 7\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 26 and depth = 7\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 25 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 29 and depth = 7\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 29 and depth = 7\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 22 and depth = 7\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 28 and depth = 7\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 27 and depth = 7\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 6478, number of negative: 57239\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.996379\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.996379\n",
      "[LightGBM] [Debug] init for col-wise cost 5.621812 seconds, init for row-wise cost 5.878859 seconds\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 5.827539 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Debug] Using Sparse Multi-Val Bin\n",
      "[LightGBM] [Info] Total Bins 330609\n",
      "[LightGBM] [Info] Number of data points in the train set: 63717, number of used features: 6549\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101668 -> initscore=-2.178824\n",
      "[LightGBM] [Info] Start training from score -2.178824\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 30 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 24 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 30 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 29 and depth = 7\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 22 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 27 and depth = 7\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 29 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 26 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 27 and depth = 7\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 28 and depth = 7\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 20 and depth = 7\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 20 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 26 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 27 and depth = 7\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 16 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 25 and depth = 7\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 22 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 25 and depth = 7\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 12956, number of negative: 114477\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.997585\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.997585\n",
      "[LightGBM] [Debug] init for col-wise cost 19.401528 seconds, init for row-wise cost 20.117301 seconds\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 20.427916 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 551029\n",
      "[LightGBM] [Info] Number of data points in the train set: 127433, number of used features: 10120\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101669 -> initscore=-2.178815\n",
      "[LightGBM] [Info] Start training from score -2.178815\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 26 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 23 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 27 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 29 and depth = 7\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "F1 на CV: 0.6259049999639668 , Best Model Hyperparameters: {'n_estimators': 60, 'max_depth': 7}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'max_depth': [1, 4, 7],\n",
    "    'n_estimators': [20, 40, 60]\n",
    "}\n",
    "\n",
    "model_lgbm = LGBMClassifier(verbose=100, random_state=12345)\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=model_lgbm, param_distributions=param_grid, cv=2, n_iter=10, scoring='f1', random_state=12345)\n",
    "random_search.fit(features_train, target_train)\n",
    "\n",
    "best_params = random_search.best_params_\n",
    "best_score = random_search.best_score_\n",
    "\n",
    "model_lgbm = LGBMClassifier(**best_params)\n",
    "\n",
    "print(\"F1 на CV:\", best_score, \", Best Model Hyperparameters:\", best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1 для LGBMBoost для кросс-валидационной выборки - 0.6259049999639668."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод**\n",
    "\n",
    "F1 для логистической регрессии на кросс-валидационной выборке составила 0.7591217971309911, что являлось самым высоким показателем среди моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тестирование"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведем тестирование для модели логистической регрессии, которая показала самое выское качество на кросс-вадиационной выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7611792918606292\n"
     ]
    }
   ],
   "source": [
    "best_model_log.fit(features_train, target_train) \n",
    "\n",
    "f1 = f1_score(target_test, best_model_log.predict(features_test))\n",
    "\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод**\n",
    "\n",
    "Показатель F1 для тестовой выборки - 0.7611792918606292. Таким образом, построенная модель со значением метрики качества F1 не меньше 0.75, что соответствует требованию заказчика."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Был представлен набор данных с разметкой о токсичности правок. Общее число наблюдений 159292, 3 столбца с признаками: unnamed, text и toxic. Последний являлся целевым признаком. Unnamed, вероятно, содержал порядковое число, однако последние значения в нем не совпадали с индексом. Toxic содержал нативный текст (без предобработки). Пропуски и явные дубликаты не были обнаружены. Классы были несбалансированны: 0 -90%, 1 - 10%.\n",
    "\n",
    "Вероятно, что часть наблюдений в столбце Unnamed была удалена, старые индексы сохранили в столбце Unnamed: 0. Задача сохранить этот столбец не стояла, поэтому далее его удалили. Однако, в дальнейшем, стоит уточнить, почему от части данных решили избавиться. \n",
    "\n",
    "Были созданы несколько выборок: обучающая и тестовая. Была выполнена векторизация текстов, для определения тональности былы применены величины TF-IDF как признаки.\n",
    "\n",
    "Были оценены следующие модели:\n",
    "- логистическая регрессия\n",
    "- дерево решений\n",
    "- случайный лес\n",
    "- CatBoost\n",
    "- LGBMBoost.\n",
    "\n",
    "Ниболее точной моделью на кросс-валидационной выборке являлась логистическая регрессия (0.7591217971309911), на тестовой выборке f1 для данной модели составил 0.7611792918606292. Таким образом, построенная модель со значением метрики качества F1 не меньше 0.75, что соответствует требованию заказчика."
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 11392,
    "start_time": "2023-11-30T04:56:00.060Z"
   },
   {
    "duration": 2571,
    "start_time": "2023-11-30T05:32:36.709Z"
   },
   {
    "duration": 2522,
    "start_time": "2023-11-30T05:32:42.636Z"
   },
   {
    "duration": 23815,
    "start_time": "2023-11-30T05:32:49.349Z"
   },
   {
    "duration": 4607,
    "start_time": "2023-11-30T05:33:13.166Z"
   },
   {
    "duration": 357,
    "start_time": "2023-11-30T05:33:17.775Z"
   },
   {
    "duration": 13,
    "start_time": "2023-11-30T05:33:19.270Z"
   },
   {
    "duration": 2129,
    "start_time": "2023-11-30T05:34:46.521Z"
   },
   {
    "duration": 24875,
    "start_time": "2023-11-30T05:34:50.551Z"
   },
   {
    "duration": 3923,
    "start_time": "2023-11-30T05:37:21.172Z"
   },
   {
    "duration": 2554,
    "start_time": "2023-11-30T05:37:25.097Z"
   },
   {
    "duration": 3575,
    "start_time": "2023-11-30T05:37:27.653Z"
   },
   {
    "duration": 1138,
    "start_time": "2023-11-30T05:37:31.231Z"
   },
   {
    "duration": 5247,
    "start_time": "2023-11-30T05:37:32.371Z"
   },
   {
    "duration": 756,
    "start_time": "2023-11-30T05:37:37.619Z"
   },
   {
    "duration": 24649,
    "start_time": "2023-11-30T05:37:38.376Z"
   },
   {
    "duration": 10,
    "start_time": "2023-11-30T05:38:03.026Z"
   },
   {
    "duration": 6,
    "start_time": "2023-11-30T05:38:03.037Z"
   },
   {
    "duration": 14,
    "start_time": "2023-11-30T05:38:03.045Z"
   },
   {
    "duration": 2,
    "start_time": "2023-11-30T05:39:40.255Z"
   },
   {
    "duration": 9,
    "start_time": "2023-11-30T05:39:49.939Z"
   },
   {
    "duration": 6,
    "start_time": "2023-11-30T05:39:53.519Z"
   },
   {
    "duration": 10,
    "start_time": "2023-11-30T05:39:58.243Z"
   },
   {
    "duration": 378,
    "start_time": "2023-11-30T05:41:10.364Z"
   },
   {
    "duration": 16,
    "start_time": "2023-11-30T05:41:21.459Z"
   },
   {
    "duration": 256,
    "start_time": "2023-11-30T05:41:38.255Z"
   },
   {
    "duration": 614,
    "start_time": "2023-11-30T05:41:54.301Z"
   },
   {
    "duration": 16003,
    "start_time": "2023-11-30T05:42:06.676Z"
   },
   {
    "duration": 46,
    "start_time": "2023-11-30T05:42:30.140Z"
   },
   {
    "duration": 31,
    "start_time": "2023-11-30T05:44:37.788Z"
   },
   {
    "duration": 600,
    "start_time": "2023-11-30T05:45:28.432Z"
   },
   {
    "duration": 5651,
    "start_time": "2023-11-30T05:45:31.132Z"
   },
   {
    "duration": 54,
    "start_time": "2023-11-30T05:45:39.029Z"
   },
   {
    "duration": 699,
    "start_time": "2023-11-30T05:46:05.863Z"
   },
   {
    "duration": 3678,
    "start_time": "2023-11-30T05:55:01.746Z"
   },
   {
    "duration": 2655,
    "start_time": "2023-11-30T05:55:05.426Z"
   },
   {
    "duration": 2,
    "start_time": "2023-11-30T05:55:08.084Z"
   },
   {
    "duration": 1198,
    "start_time": "2023-11-30T05:55:08.088Z"
   },
   {
    "duration": 2185,
    "start_time": "2023-11-30T05:55:09.288Z"
   },
   {
    "duration": 0,
    "start_time": "2023-11-30T05:55:11.474Z"
   },
   {
    "duration": 0,
    "start_time": "2023-11-30T05:55:11.475Z"
   },
   {
    "duration": 0,
    "start_time": "2023-11-30T05:55:11.476Z"
   },
   {
    "duration": 0,
    "start_time": "2023-11-30T05:55:11.477Z"
   },
   {
    "duration": 0,
    "start_time": "2023-11-30T05:55:11.478Z"
   },
   {
    "duration": 0,
    "start_time": "2023-11-30T05:55:11.479Z"
   },
   {
    "duration": 0,
    "start_time": "2023-11-30T05:55:11.479Z"
   },
   {
    "duration": 0,
    "start_time": "2023-11-30T05:55:11.480Z"
   },
   {
    "duration": 0,
    "start_time": "2023-11-30T05:55:11.481Z"
   },
   {
    "duration": 2833,
    "start_time": "2023-11-30T05:55:32.384Z"
   },
   {
    "duration": 2182,
    "start_time": "2023-11-30T05:55:36.204Z"
   },
   {
    "duration": 2,
    "start_time": "2023-11-30T05:55:38.387Z"
   },
   {
    "duration": 10,
    "start_time": "2023-11-30T05:55:41.288Z"
   },
   {
    "duration": 7,
    "start_time": "2023-11-30T05:55:41.979Z"
   },
   {
    "duration": 11,
    "start_time": "2023-11-30T05:55:43.579Z"
   },
   {
    "duration": 12,
    "start_time": "2023-11-30T05:55:44.327Z"
   },
   {
    "duration": 89,
    "start_time": "2023-11-30T05:55:53.732Z"
   },
   {
    "duration": 89,
    "start_time": "2023-11-30T05:56:14.399Z"
   },
   {
    "duration": 101,
    "start_time": "2023-11-30T05:56:29.203Z"
   },
   {
    "duration": 463,
    "start_time": "2023-11-30T05:56:49.437Z"
   },
   {
    "duration": 750,
    "start_time": "2023-11-30T05:57:00.249Z"
   },
   {
    "duration": 16004,
    "start_time": "2023-11-30T05:57:03.911Z"
   },
   {
    "duration": 45,
    "start_time": "2023-11-30T05:57:48.068Z"
   },
   {
    "duration": 66,
    "start_time": "2023-11-30T06:06:28.568Z"
   },
   {
    "duration": 166,
    "start_time": "2023-11-30T06:09:18.163Z"
   },
   {
    "duration": 39,
    "start_time": "2023-11-30T06:09:35.275Z"
   },
   {
    "duration": 48,
    "start_time": "2023-11-30T06:10:04.699Z"
   },
   {
    "duration": 40,
    "start_time": "2023-11-30T06:11:46.171Z"
   },
   {
    "duration": 38,
    "start_time": "2023-11-30T06:12:39.055Z"
   },
   {
    "duration": 38,
    "start_time": "2023-11-30T06:13:25.894Z"
   },
   {
    "duration": 44,
    "start_time": "2023-11-30T06:14:24.964Z"
   },
   {
    "duration": 2654,
    "start_time": "2023-11-30T06:16:30.379Z"
   },
   {
    "duration": 2579,
    "start_time": "2023-11-30T06:16:33.034Z"
   },
   {
    "duration": 3,
    "start_time": "2023-11-30T06:16:35.614Z"
   },
   {
    "duration": 1051,
    "start_time": "2023-11-30T06:16:35.619Z"
   },
   {
    "duration": 3544,
    "start_time": "2023-11-30T06:16:36.671Z"
   },
   {
    "duration": 789,
    "start_time": "2023-11-30T06:16:40.216Z"
   },
   {
    "duration": 2,
    "start_time": "2023-11-30T06:16:41.006Z"
   },
   {
    "duration": 12,
    "start_time": "2023-11-30T06:16:41.014Z"
   },
   {
    "duration": 8,
    "start_time": "2023-11-30T06:16:41.027Z"
   },
   {
    "duration": 10,
    "start_time": "2023-11-30T06:16:41.037Z"
   },
   {
    "duration": 15,
    "start_time": "2023-11-30T06:16:41.048Z"
   },
   {
    "duration": 744,
    "start_time": "2023-11-30T06:16:41.064Z"
   },
   {
    "duration": 1980,
    "start_time": "2023-11-30T06:16:41.810Z"
   },
   {
    "duration": 303,
    "start_time": "2023-11-30T06:16:43.792Z"
   },
   {
    "duration": 39,
    "start_time": "2023-11-30T06:20:42.919Z"
   },
   {
    "duration": 40,
    "start_time": "2023-11-30T06:20:50.171Z"
   },
   {
    "duration": 2693,
    "start_time": "2023-11-30T06:21:29.317Z"
   },
   {
    "duration": 2627,
    "start_time": "2023-11-30T06:21:32.012Z"
   },
   {
    "duration": 3,
    "start_time": "2023-11-30T06:21:34.640Z"
   },
   {
    "duration": 1038,
    "start_time": "2023-11-30T06:21:34.644Z"
   },
   {
    "duration": 3462,
    "start_time": "2023-11-30T06:21:35.683Z"
   },
   {
    "duration": 752,
    "start_time": "2023-11-30T06:21:39.146Z"
   },
   {
    "duration": 2,
    "start_time": "2023-11-30T06:21:39.899Z"
   },
   {
    "duration": 16,
    "start_time": "2023-11-30T06:21:39.902Z"
   },
   {
    "duration": 13,
    "start_time": "2023-11-30T06:21:39.919Z"
   },
   {
    "duration": 9,
    "start_time": "2023-11-30T06:21:39.934Z"
   },
   {
    "duration": 18,
    "start_time": "2023-11-30T06:21:39.945Z"
   },
   {
    "duration": 675,
    "start_time": "2023-11-30T06:21:39.964Z"
   },
   {
    "duration": 1958,
    "start_time": "2023-11-30T06:21:40.641Z"
   },
   {
    "duration": 305,
    "start_time": "2023-11-30T06:21:42.601Z"
   },
   {
    "duration": 37,
    "start_time": "2023-11-30T06:23:55.191Z"
   },
   {
    "duration": 42,
    "start_time": "2023-11-30T06:24:56.566Z"
   },
   {
    "duration": 2656,
    "start_time": "2023-11-30T06:25:19.565Z"
   },
   {
    "duration": 2593,
    "start_time": "2023-11-30T06:25:22.223Z"
   },
   {
    "duration": 2,
    "start_time": "2023-11-30T06:25:24.818Z"
   },
   {
    "duration": 1051,
    "start_time": "2023-11-30T06:25:24.821Z"
   },
   {
    "duration": 3209,
    "start_time": "2023-11-30T06:25:25.874Z"
   },
   {
    "duration": 744,
    "start_time": "2023-11-30T06:25:29.084Z"
   },
   {
    "duration": 1,
    "start_time": "2023-11-30T06:25:29.830Z"
   },
   {
    "duration": 10,
    "start_time": "2023-11-30T06:25:29.832Z"
   },
   {
    "duration": 6,
    "start_time": "2023-11-30T06:25:29.843Z"
   },
   {
    "duration": 8,
    "start_time": "2023-11-30T06:25:29.850Z"
   },
   {
    "duration": 16,
    "start_time": "2023-11-30T06:25:29.859Z"
   },
   {
    "duration": 652,
    "start_time": "2023-11-30T06:25:29.876Z"
   },
   {
    "duration": 1954,
    "start_time": "2023-11-30T06:25:30.529Z"
   },
   {
    "duration": 299,
    "start_time": "2023-11-30T06:25:32.484Z"
   },
   {
    "duration": 43,
    "start_time": "2023-11-30T06:32:52.175Z"
   },
   {
    "duration": 2644,
    "start_time": "2023-11-30T06:34:34.695Z"
   },
   {
    "duration": 2579,
    "start_time": "2023-11-30T06:34:37.341Z"
   },
   {
    "duration": 2,
    "start_time": "2023-11-30T06:34:39.922Z"
   },
   {
    "duration": 1071,
    "start_time": "2023-11-30T06:34:39.925Z"
   },
   {
    "duration": 3287,
    "start_time": "2023-11-30T06:34:40.997Z"
   },
   {
    "duration": 738,
    "start_time": "2023-11-30T06:34:44.285Z"
   },
   {
    "duration": 2,
    "start_time": "2023-11-30T06:34:45.024Z"
   },
   {
    "duration": 33,
    "start_time": "2023-11-30T06:34:45.027Z"
   },
   {
    "duration": 11,
    "start_time": "2023-11-30T06:34:45.061Z"
   },
   {
    "duration": 11,
    "start_time": "2023-11-30T06:34:45.074Z"
   },
   {
    "duration": 20,
    "start_time": "2023-11-30T06:34:45.086Z"
   },
   {
    "duration": 628,
    "start_time": "2023-11-30T06:34:45.107Z"
   },
   {
    "duration": 1978,
    "start_time": "2023-11-30T06:34:45.737Z"
   },
   {
    "duration": 297,
    "start_time": "2023-11-30T06:34:47.716Z"
   },
   {
    "duration": 11105,
    "start_time": "2023-12-01T09:51:55.921Z"
   },
   {
    "duration": 2541,
    "start_time": "2023-12-01T09:52:07.029Z"
   },
   {
    "duration": 22504,
    "start_time": "2023-12-01T09:52:09.572Z"
   },
   {
    "duration": 2,
    "start_time": "2023-12-01T09:52:32.078Z"
   },
   {
    "duration": 3498,
    "start_time": "2023-12-01T09:52:32.082Z"
   },
   {
    "duration": 2163,
    "start_time": "2023-12-01T09:52:35.582Z"
   },
   {
    "duration": 2,
    "start_time": "2023-12-01T09:52:37.746Z"
   },
   {
    "duration": 12,
    "start_time": "2023-12-01T09:52:37.749Z"
   },
   {
    "duration": 5,
    "start_time": "2023-12-01T09:52:37.762Z"
   },
   {
    "duration": 10,
    "start_time": "2023-12-01T09:52:37.769Z"
   },
   {
    "duration": 15,
    "start_time": "2023-12-01T09:52:37.780Z"
   },
   {
    "duration": 823,
    "start_time": "2023-12-01T09:52:37.796Z"
   },
   {
    "duration": 15391,
    "start_time": "2023-12-01T09:52:38.620Z"
   },
   {
    "duration": 307,
    "start_time": "2023-12-01T09:52:54.012Z"
   },
   {
    "duration": 1303,
    "start_time": "2023-12-01T09:53:06.645Z"
   },
   {
    "duration": 744,
    "start_time": "2023-12-01T09:53:09.221Z"
   },
   {
    "duration": 4273,
    "start_time": "2023-12-01T09:53:44.265Z"
   },
   {
    "duration": 2601,
    "start_time": "2023-12-01T09:53:48.540Z"
   },
   {
    "duration": 3573,
    "start_time": "2023-12-01T09:53:51.143Z"
   },
   {
    "duration": 3,
    "start_time": "2023-12-01T09:53:54.718Z"
   },
   {
    "duration": 6027,
    "start_time": "2023-12-01T09:53:54.723Z"
   },
   {
    "duration": 2173,
    "start_time": "2023-12-01T09:54:00.751Z"
   },
   {
    "duration": 25017,
    "start_time": "2023-12-01T09:54:02.926Z"
   },
   {
    "duration": 10,
    "start_time": "2023-12-01T09:54:27.944Z"
   },
   {
    "duration": 16,
    "start_time": "2023-12-01T09:54:27.955Z"
   },
   {
    "duration": 15,
    "start_time": "2023-12-01T09:54:27.972Z"
   },
   {
    "duration": 23,
    "start_time": "2023-12-01T09:54:27.989Z"
   },
   {
    "duration": 776,
    "start_time": "2023-12-01T09:54:28.013Z"
   },
   {
    "duration": 15446,
    "start_time": "2023-12-01T09:54:28.791Z"
   },
   {
    "duration": 3,
    "start_time": "2023-12-01T09:54:44.241Z"
   },
   {
    "duration": 3519,
    "start_time": "2023-12-01T10:27:43.964Z"
   },
   {
    "duration": 2634,
    "start_time": "2023-12-01T10:27:47.485Z"
   },
   {
    "duration": 3329,
    "start_time": "2023-12-01T10:27:50.121Z"
   },
   {
    "duration": 770,
    "start_time": "2023-12-01T10:27:54.628Z"
   },
   {
    "duration": 6,
    "start_time": "2023-12-01T10:28:16.713Z"
   },
   {
    "duration": 10,
    "start_time": "2023-12-01T10:28:24.469Z"
   },
   {
    "duration": 2712,
    "start_time": "2023-12-01T10:28:45.333Z"
   },
   {
    "duration": 2704,
    "start_time": "2023-12-01T10:34:06.285Z"
   },
   {
    "duration": 2719,
    "start_time": "2023-12-01T10:34:08.991Z"
   },
   {
    "duration": 12485,
    "start_time": "2023-12-01T10:34:54.368Z"
   },
   {
    "duration": 3778,
    "start_time": "2023-12-01T10:35:34.448Z"
   },
   {
    "duration": 751,
    "start_time": "2023-12-01T10:35:40.552Z"
   },
   {
    "duration": 7,
    "start_time": "2023-12-01T10:35:42.604Z"
   },
   {
    "duration": 12,
    "start_time": "2023-12-01T10:35:45.444Z"
   },
   {
    "duration": 1618,
    "start_time": "2023-12-01T10:36:43.616Z"
   },
   {
    "duration": 2679,
    "start_time": "2023-12-01T10:38:46.588Z"
   },
   {
    "duration": 2637,
    "start_time": "2023-12-01T10:38:49.269Z"
   },
   {
    "duration": 10197,
    "start_time": "2023-12-01T10:38:51.908Z"
   },
   {
    "duration": 3753,
    "start_time": "2023-12-01T10:39:02.107Z"
   },
   {
    "duration": 763,
    "start_time": "2023-12-01T10:39:05.861Z"
   },
   {
    "duration": 7,
    "start_time": "2023-12-01T10:39:09.504Z"
   },
   {
    "duration": 11,
    "start_time": "2023-12-01T10:39:11.752Z"
   },
   {
    "duration": 1824,
    "start_time": "2023-12-01T10:39:13.692Z"
   },
   {
    "duration": 1689,
    "start_time": "2023-12-01T10:41:29.857Z"
   },
   {
    "duration": 14,
    "start_time": "2023-12-01T10:43:11.421Z"
   },
   {
    "duration": 1408,
    "start_time": "2023-12-01T10:43:23.753Z"
   },
   {
    "duration": 10005,
    "start_time": "2023-12-01T10:44:19.030Z"
   },
   {
    "duration": 3897,
    "start_time": "2023-12-01T10:44:29.037Z"
   },
   {
    "duration": 765,
    "start_time": "2023-12-01T10:44:32.936Z"
   },
   {
    "duration": 8,
    "start_time": "2023-12-01T10:44:41.610Z"
   },
   {
    "duration": 13,
    "start_time": "2023-12-01T10:44:46.363Z"
   },
   {
    "duration": 1756,
    "start_time": "2023-12-01T10:44:47.299Z"
   },
   {
    "duration": 14,
    "start_time": "2023-12-01T10:46:04.822Z"
   },
   {
    "duration": 1625,
    "start_time": "2023-12-01T10:46:10.391Z"
   },
   {
    "duration": 11291,
    "start_time": "2023-12-01T10:48:04.075Z"
   },
   {
    "duration": 3574,
    "start_time": "2023-12-01T10:48:15.369Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-01T10:48:18.944Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-01T10:48:18.945Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-01T10:48:18.946Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-01T10:48:18.947Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-01T10:48:18.948Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-01T10:48:18.948Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-01T10:48:18.949Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-01T10:48:18.950Z"
   },
   {
    "duration": 13794,
    "start_time": "2023-12-01T10:52:31.508Z"
   },
   {
    "duration": 848,
    "start_time": "2023-12-01T10:52:46.752Z"
   },
   {
    "duration": 2786,
    "start_time": "2023-12-01T11:00:00.043Z"
   },
   {
    "duration": 3929,
    "start_time": "2023-12-01T11:00:02.831Z"
   },
   {
    "duration": 815,
    "start_time": "2023-12-01T11:00:11.256Z"
   },
   {
    "duration": 7,
    "start_time": "2023-12-01T11:00:13.056Z"
   },
   {
    "duration": 11,
    "start_time": "2023-12-01T11:00:17.744Z"
   },
   {
    "duration": 2315,
    "start_time": "2023-12-01T11:00:18.900Z"
   },
   {
    "duration": 2995,
    "start_time": "2023-12-01T11:00:46.176Z"
   },
   {
    "duration": 1370,
    "start_time": "2023-12-01T11:01:02.144Z"
   },
   {
    "duration": 1443,
    "start_time": "2023-12-01T11:01:32.260Z"
   },
   {
    "duration": 1442,
    "start_time": "2023-12-01T11:01:38.085Z"
   },
   {
    "duration": 7764,
    "start_time": "2023-12-01T11:06:56.601Z"
   },
   {
    "duration": 3744,
    "start_time": "2023-12-01T11:07:04.367Z"
   },
   {
    "duration": 757,
    "start_time": "2023-12-01T11:07:08.112Z"
   },
   {
    "duration": 6,
    "start_time": "2023-12-01T11:07:08.870Z"
   },
   {
    "duration": 9,
    "start_time": "2023-12-01T11:07:08.877Z"
   },
   {
    "duration": 8563,
    "start_time": "2023-12-01T11:07:08.887Z"
   },
   {
    "duration": 534,
    "start_time": "2023-12-01T11:07:17.452Z"
   },
   {
    "duration": 2292,
    "start_time": "2023-12-01T11:07:17.988Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-01T11:07:20.282Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-01T11:07:20.283Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-01T11:07:20.284Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-01T11:07:20.286Z"
   },
   {
    "duration": 78,
    "start_time": "2023-12-01T11:13:04.903Z"
   },
   {
    "duration": 3,
    "start_time": "2023-12-01T11:14:05.591Z"
   },
   {
    "duration": 5781,
    "start_time": "2023-12-01T11:14:05.596Z"
   },
   {
    "duration": 2109,
    "start_time": "2023-12-01T11:14:11.379Z"
   },
   {
    "duration": 6,
    "start_time": "2023-12-01T11:14:13.489Z"
   },
   {
    "duration": 11,
    "start_time": "2023-12-01T11:14:13.497Z"
   },
   {
    "duration": 2987,
    "start_time": "2023-12-01T11:14:13.509Z"
   },
   {
    "duration": 638,
    "start_time": "2023-12-01T11:14:16.497Z"
   },
   {
    "duration": 1993,
    "start_time": "2023-12-01T11:14:17.136Z"
   },
   {
    "duration": 12,
    "start_time": "2023-12-01T11:14:19.130Z"
   },
   {
    "duration": 730,
    "start_time": "2023-12-01T11:14:19.143Z"
   },
   {
    "duration": 45,
    "start_time": "2023-12-01T11:16:00.431Z"
   },
   {
    "duration": 4,
    "start_time": "2023-12-01T11:16:20.350Z"
   },
   {
    "duration": 5202,
    "start_time": "2023-12-01T11:16:20.990Z"
   },
   {
    "duration": 2078,
    "start_time": "2023-12-01T11:16:27.714Z"
   },
   {
    "duration": 6,
    "start_time": "2023-12-01T11:16:29.793Z"
   },
   {
    "duration": 10,
    "start_time": "2023-12-01T11:16:29.800Z"
   },
   {
    "duration": 3038,
    "start_time": "2023-12-01T11:16:30.334Z"
   },
   {
    "duration": 2591,
    "start_time": "2023-12-01T11:16:33.374Z"
   },
   {
    "duration": 298,
    "start_time": "2023-12-01T11:19:29.150Z"
   },
   {
    "duration": 15,
    "start_time": "2023-12-01T11:19:45.590Z"
   },
   {
    "duration": 3,
    "start_time": "2023-12-01T11:33:44.353Z"
   },
   {
    "duration": 3556,
    "start_time": "2023-12-01T11:33:45.633Z"
   },
   {
    "duration": 737,
    "start_time": "2023-12-01T11:33:49.190Z"
   },
   {
    "duration": 6,
    "start_time": "2023-12-01T11:33:54.001Z"
   },
   {
    "duration": 10,
    "start_time": "2023-12-01T11:33:57.418Z"
   },
   {
    "duration": 2,
    "start_time": "2023-12-01T11:33:58.622Z"
   },
   {
    "duration": 2456,
    "start_time": "2023-12-01T11:34:00.510Z"
   },
   {
    "duration": 645,
    "start_time": "2023-12-01T11:37:35.899Z"
   },
   {
    "duration": 607,
    "start_time": "2023-12-01T11:38:35.391Z"
   },
   {
    "duration": 3,
    "start_time": "2023-12-01T11:39:36.019Z"
   },
   {
    "duration": 5272,
    "start_time": "2023-12-01T11:39:36.023Z"
   },
   {
    "duration": 2086,
    "start_time": "2023-12-01T11:39:41.297Z"
   },
   {
    "duration": 6,
    "start_time": "2023-12-01T11:39:43.385Z"
   },
   {
    "duration": 10,
    "start_time": "2023-12-01T11:39:43.392Z"
   },
   {
    "duration": 2,
    "start_time": "2023-12-01T11:39:43.403Z"
   },
   {
    "duration": 3207,
    "start_time": "2023-12-01T11:39:43.406Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-01T11:39:46.615Z"
   },
   {
    "duration": 2,
    "start_time": "2023-12-01T11:41:44.647Z"
   },
   {
    "duration": 5674,
    "start_time": "2023-12-01T11:41:44.651Z"
   },
   {
    "duration": 2123,
    "start_time": "2023-12-01T11:41:50.327Z"
   },
   {
    "duration": 6,
    "start_time": "2023-12-01T11:41:52.451Z"
   },
   {
    "duration": 9,
    "start_time": "2023-12-01T11:41:52.459Z"
   },
   {
    "duration": 4,
    "start_time": "2023-12-01T11:41:52.469Z"
   },
   {
    "duration": 2414,
    "start_time": "2023-12-01T11:41:52.474Z"
   },
   {
    "duration": 119,
    "start_time": "2023-12-01T11:41:54.889Z"
   },
   {
    "duration": 12,
    "start_time": "2023-12-01T11:41:55.010Z"
   },
   {
    "duration": 2,
    "start_time": "2023-12-01T11:42:29.684Z"
   },
   {
    "duration": 6127,
    "start_time": "2023-12-01T11:42:29.688Z"
   },
   {
    "duration": 2090,
    "start_time": "2023-12-01T11:42:35.817Z"
   },
   {
    "duration": 7,
    "start_time": "2023-12-01T11:42:37.908Z"
   },
   {
    "duration": 9,
    "start_time": "2023-12-01T11:42:37.916Z"
   },
   {
    "duration": 12,
    "start_time": "2023-12-01T11:42:37.926Z"
   },
   {
    "duration": 2424,
    "start_time": "2023-12-01T11:42:37.939Z"
   },
   {
    "duration": 225,
    "start_time": "2023-12-01T11:42:40.364Z"
   },
   {
    "duration": 11,
    "start_time": "2023-12-01T11:42:40.590Z"
   },
   {
    "duration": 4,
    "start_time": "2023-12-01T11:47:37.317Z"
   },
   {
    "duration": 4,
    "start_time": "2023-12-02T04:10:01.758Z"
   },
   {
    "duration": 4663,
    "start_time": "2023-12-02T04:10:02.885Z"
   },
   {
    "duration": 2305,
    "start_time": "2023-12-02T04:10:09.394Z"
   },
   {
    "duration": 9,
    "start_time": "2023-12-02T04:10:16.256Z"
   },
   {
    "duration": 16,
    "start_time": "2023-12-02T04:10:18.539Z"
   },
   {
    "duration": 4,
    "start_time": "2023-12-02T04:19:21.047Z"
   },
   {
    "duration": 4564,
    "start_time": "2023-12-02T04:19:21.871Z"
   },
   {
    "duration": 890,
    "start_time": "2023-12-02T04:19:26.437Z"
   },
   {
    "duration": 14,
    "start_time": "2023-12-02T04:19:27.329Z"
   },
   {
    "duration": 15,
    "start_time": "2023-12-02T04:19:29.086Z"
   },
   {
    "duration": 2344,
    "start_time": "2023-12-02T04:19:30.431Z"
   },
   {
    "duration": 3,
    "start_time": "2023-12-02T04:19:33.758Z"
   },
   {
    "duration": 356,
    "start_time": "2023-12-02T04:19:34.618Z"
   },
   {
    "duration": 16,
    "start_time": "2023-12-02T04:19:47.339Z"
   },
   {
    "duration": 17,
    "start_time": "2023-12-02T04:20:04.760Z"
   },
   {
    "duration": 4,
    "start_time": "2023-12-02T04:20:40.777Z"
   },
   {
    "duration": 4597,
    "start_time": "2023-12-02T04:20:40.783Z"
   },
   {
    "duration": 2244,
    "start_time": "2023-12-02T04:20:45.382Z"
   },
   {
    "duration": 7,
    "start_time": "2023-12-02T04:20:47.628Z"
   },
   {
    "duration": 21,
    "start_time": "2023-12-02T04:20:47.637Z"
   },
   {
    "duration": 2389,
    "start_time": "2023-12-02T04:20:47.659Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-02T04:20:50.049Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-02T04:20:50.050Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-02T04:20:50.051Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-02T04:20:50.052Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-02T04:20:50.053Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-02T04:20:50.054Z"
   },
   {
    "duration": 48,
    "start_time": "2023-12-02T04:21:31.566Z"
   },
   {
    "duration": 3,
    "start_time": "2023-12-02T04:21:42.955Z"
   },
   {
    "duration": 4490,
    "start_time": "2023-12-02T04:21:43.487Z"
   },
   {
    "duration": 2288,
    "start_time": "2023-12-02T04:21:47.979Z"
   },
   {
    "duration": 7,
    "start_time": "2023-12-02T04:21:50.268Z"
   },
   {
    "duration": 13,
    "start_time": "2023-12-02T04:21:50.276Z"
   },
   {
    "duration": 2057,
    "start_time": "2023-12-02T04:21:50.290Z"
   },
   {
    "duration": 3,
    "start_time": "2023-12-02T04:22:41.292Z"
   },
   {
    "duration": 314,
    "start_time": "2023-12-02T04:22:51.784Z"
   },
   {
    "duration": 3,
    "start_time": "2023-12-02T04:26:55.029Z"
   },
   {
    "duration": 4311,
    "start_time": "2023-12-02T04:26:55.200Z"
   },
   {
    "duration": 893,
    "start_time": "2023-12-02T04:26:59.513Z"
   },
   {
    "duration": 8,
    "start_time": "2023-12-02T04:27:00.407Z"
   },
   {
    "duration": 43,
    "start_time": "2023-12-02T04:27:00.416Z"
   },
   {
    "duration": 2157,
    "start_time": "2023-12-02T04:27:00.460Z"
   },
   {
    "duration": 5,
    "start_time": "2023-12-02T04:27:02.619Z"
   },
   {
    "duration": 520,
    "start_time": "2023-12-02T04:27:04.028Z"
   },
   {
    "duration": 46,
    "start_time": "2023-12-02T04:33:52.384Z"
   },
   {
    "duration": 3,
    "start_time": "2023-12-02T04:34:06.577Z"
   },
   {
    "duration": 4602,
    "start_time": "2023-12-02T04:34:07.174Z"
   },
   {
    "duration": 2280,
    "start_time": "2023-12-02T04:34:11.778Z"
   },
   {
    "duration": 7,
    "start_time": "2023-12-02T04:34:14.060Z"
   },
   {
    "duration": 21,
    "start_time": "2023-12-02T04:34:14.068Z"
   },
   {
    "duration": 2152,
    "start_time": "2023-12-02T04:34:14.091Z"
   },
   {
    "duration": 3,
    "start_time": "2023-12-02T04:34:16.244Z"
   },
   {
    "duration": 532,
    "start_time": "2023-12-02T04:34:16.249Z"
   },
   {
    "duration": 9938,
    "start_time": "2023-12-02T04:34:17.349Z"
   },
   {
    "duration": 314,
    "start_time": "2023-12-02T04:35:55.209Z"
   },
   {
    "duration": 3,
    "start_time": "2023-12-02T04:36:26.028Z"
   },
   {
    "duration": 4381,
    "start_time": "2023-12-02T04:36:26.207Z"
   },
   {
    "duration": 886,
    "start_time": "2023-12-02T04:36:30.590Z"
   },
   {
    "duration": 10,
    "start_time": "2023-12-02T04:36:33.791Z"
   },
   {
    "duration": 14,
    "start_time": "2023-12-02T04:36:34.226Z"
   },
   {
    "duration": 2137,
    "start_time": "2023-12-02T04:36:34.431Z"
   },
   {
    "duration": 11,
    "start_time": "2023-12-02T04:36:36.570Z"
   },
   {
    "duration": 506,
    "start_time": "2023-12-02T04:36:36.583Z"
   },
   {
    "duration": 9915,
    "start_time": "2023-12-02T04:36:37.091Z"
   },
   {
    "duration": 11043,
    "start_time": "2023-12-02T04:36:47.007Z"
   },
   {
    "duration": 6,
    "start_time": "2023-12-02T04:40:30.072Z"
   },
   {
    "duration": 4,
    "start_time": "2023-12-02T04:44:05.942Z"
   },
   {
    "duration": 4487,
    "start_time": "2023-12-02T04:44:06.695Z"
   },
   {
    "duration": 889,
    "start_time": "2023-12-02T04:44:11.184Z"
   },
   {
    "duration": 7,
    "start_time": "2023-12-02T04:44:12.075Z"
   },
   {
    "duration": 15,
    "start_time": "2023-12-02T04:44:12.452Z"
   },
   {
    "duration": 3,
    "start_time": "2023-12-02T04:44:31.141Z"
   },
   {
    "duration": 4,
    "start_time": "2023-12-02T04:45:52.219Z"
   },
   {
    "duration": 4609,
    "start_time": "2023-12-02T04:45:52.402Z"
   },
   {
    "duration": 2266,
    "start_time": "2023-12-02T04:45:57.012Z"
   },
   {
    "duration": 7,
    "start_time": "2023-12-02T04:45:59.279Z"
   },
   {
    "duration": 14,
    "start_time": "2023-12-02T04:45:59.288Z"
   },
   {
    "duration": 2110,
    "start_time": "2023-12-02T04:45:59.304Z"
   },
   {
    "duration": 3,
    "start_time": "2023-12-02T04:46:08.018Z"
   },
   {
    "duration": 531,
    "start_time": "2023-12-02T04:46:16.586Z"
   },
   {
    "duration": 10321,
    "start_time": "2023-12-02T04:46:33.277Z"
   },
   {
    "duration": 11163,
    "start_time": "2023-12-02T04:46:45.388Z"
   },
   {
    "duration": 336,
    "start_time": "2023-12-02T04:47:46.699Z"
   },
   {
    "duration": 3,
    "start_time": "2023-12-02T04:48:12.489Z"
   },
   {
    "duration": 1679,
    "start_time": "2023-12-02T04:48:22.865Z"
   },
   {
    "duration": 1722,
    "start_time": "2023-12-02T04:52:19.754Z"
   },
   {
    "duration": 4,
    "start_time": "2023-12-02T04:53:05.552Z"
   },
   {
    "duration": 27,
    "start_time": "2023-12-02T04:53:13.444Z"
   },
   {
    "duration": 4,
    "start_time": "2023-12-02T04:54:24.042Z"
   },
   {
    "duration": 4370,
    "start_time": "2023-12-02T04:54:24.048Z"
   },
   {
    "duration": 874,
    "start_time": "2023-12-02T04:54:28.420Z"
   },
   {
    "duration": 6,
    "start_time": "2023-12-02T04:54:29.296Z"
   },
   {
    "duration": 15,
    "start_time": "2023-12-02T04:54:29.304Z"
   },
   {
    "duration": 2114,
    "start_time": "2023-12-02T04:54:29.320Z"
   },
   {
    "duration": 29,
    "start_time": "2023-12-02T04:54:31.435Z"
   },
   {
    "duration": 554,
    "start_time": "2023-12-02T04:54:31.465Z"
   },
   {
    "duration": 9994,
    "start_time": "2023-12-02T04:54:32.021Z"
   },
   {
    "duration": 10453,
    "start_time": "2023-12-02T04:54:42.017Z"
   },
   {
    "duration": 4,
    "start_time": "2023-12-02T04:54:52.471Z"
   },
   {
    "duration": 1706,
    "start_time": "2023-12-02T04:54:52.477Z"
   },
   {
    "duration": 1702,
    "start_time": "2023-12-02T04:54:54.184Z"
   },
   {
    "duration": 1683,
    "start_time": "2023-12-02T04:54:55.889Z"
   },
   {
    "duration": 4,
    "start_time": "2023-12-02T04:56:18.588Z"
   },
   {
    "duration": 1690,
    "start_time": "2023-12-02T04:56:24.390Z"
   },
   {
    "duration": 334,
    "start_time": "2023-12-02T04:58:22.773Z"
   },
   {
    "duration": 3,
    "start_time": "2023-12-02T04:59:48.654Z"
   },
   {
    "duration": 4670,
    "start_time": "2023-12-02T04:59:48.659Z"
   },
   {
    "duration": 856,
    "start_time": "2023-12-02T04:59:53.331Z"
   },
   {
    "duration": 7,
    "start_time": "2023-12-02T04:59:54.189Z"
   },
   {
    "duration": 14,
    "start_time": "2023-12-02T04:59:54.197Z"
   },
   {
    "duration": 2100,
    "start_time": "2023-12-02T04:59:54.212Z"
   },
   {
    "duration": 14,
    "start_time": "2023-12-02T04:59:56.314Z"
   },
   {
    "duration": 528,
    "start_time": "2023-12-02T04:59:56.329Z"
   },
   {
    "duration": 10351,
    "start_time": "2023-12-02T04:59:56.859Z"
   },
   {
    "duration": 11477,
    "start_time": "2023-12-02T05:00:07.212Z"
   },
   {
    "duration": 5,
    "start_time": "2023-12-02T05:00:18.690Z"
   },
   {
    "duration": 1763,
    "start_time": "2023-12-02T05:00:18.696Z"
   },
   {
    "duration": 1762,
    "start_time": "2023-12-02T05:00:20.461Z"
   },
   {
    "duration": 5,
    "start_time": "2023-12-02T05:00:22.225Z"
   },
   {
    "duration": 20,
    "start_time": "2023-12-02T05:00:22.231Z"
   },
   {
    "duration": 348,
    "start_time": "2023-12-02T05:00:22.253Z"
   },
   {
    "duration": 861,
    "start_time": "2023-12-02T05:00:45.412Z"
   },
   {
    "duration": 10,
    "start_time": "2023-12-02T05:00:59.165Z"
   },
   {
    "duration": 872,
    "start_time": "2023-12-02T05:01:06.178Z"
   },
   {
    "duration": 26,
    "start_time": "2023-12-02T05:01:36.821Z"
   },
   {
    "duration": 24,
    "start_time": "2023-12-02T05:01:55.063Z"
   },
   {
    "duration": 26,
    "start_time": "2023-12-02T05:07:21.284Z"
   },
   {
    "duration": 3,
    "start_time": "2023-12-02T05:11:12.995Z"
   },
   {
    "duration": 4436,
    "start_time": "2023-12-02T05:11:13.165Z"
   },
   {
    "duration": 862,
    "start_time": "2023-12-02T05:11:17.603Z"
   },
   {
    "duration": 7,
    "start_time": "2023-12-02T05:11:18.467Z"
   },
   {
    "duration": 36,
    "start_time": "2023-12-02T05:11:18.475Z"
   },
   {
    "duration": 2139,
    "start_time": "2023-12-02T05:11:18.513Z"
   },
   {
    "duration": 6,
    "start_time": "2023-12-02T05:11:20.654Z"
   },
   {
    "duration": 517,
    "start_time": "2023-12-02T05:11:20.692Z"
   },
   {
    "duration": 10201,
    "start_time": "2023-12-02T05:11:24.202Z"
   },
   {
    "duration": 10700,
    "start_time": "2023-12-02T05:11:34.404Z"
   },
   {
    "duration": 4,
    "start_time": "2023-12-02T05:11:45.105Z"
   },
   {
    "duration": 1646,
    "start_time": "2023-12-02T05:11:45.111Z"
   },
   {
    "duration": 1691,
    "start_time": "2023-12-02T05:11:50.182Z"
   },
   {
    "duration": 5,
    "start_time": "2023-12-02T05:11:53.081Z"
   },
   {
    "duration": 7,
    "start_time": "2023-12-02T05:11:55.589Z"
   },
   {
    "duration": 477,
    "start_time": "2023-12-02T05:12:03.033Z"
   },
   {
    "duration": 3,
    "start_time": "2023-12-02T05:14:18.878Z"
   },
   {
    "duration": 4544,
    "start_time": "2023-12-02T05:14:19.695Z"
   },
   {
    "duration": 862,
    "start_time": "2023-12-02T05:14:24.240Z"
   },
   {
    "duration": 6,
    "start_time": "2023-12-02T05:14:25.104Z"
   },
   {
    "duration": 42,
    "start_time": "2023-12-02T05:14:25.112Z"
   },
   {
    "duration": 2167,
    "start_time": "2023-12-02T05:14:25.337Z"
   },
   {
    "duration": 20,
    "start_time": "2023-12-02T05:14:27.506Z"
   },
   {
    "duration": 542,
    "start_time": "2023-12-02T05:14:31.809Z"
   },
   {
    "duration": 311,
    "start_time": "2023-12-02T05:14:33.821Z"
   },
   {
    "duration": 97,
    "start_time": "2023-12-02T05:16:09.867Z"
   },
   {
    "duration": 88,
    "start_time": "2023-12-02T05:16:24.887Z"
   },
   {
    "duration": 68,
    "start_time": "2023-12-02T05:16:34.031Z"
   },
   {
    "duration": 37,
    "start_time": "2023-12-02T05:16:39.576Z"
   },
   {
    "duration": 37,
    "start_time": "2023-12-02T05:18:32.048Z"
   },
   {
    "duration": 4,
    "start_time": "2023-12-02T05:18:59.648Z"
   },
   {
    "duration": 4571,
    "start_time": "2023-12-02T05:18:59.846Z"
   },
   {
    "duration": 904,
    "start_time": "2023-12-02T05:19:04.418Z"
   },
   {
    "duration": 8,
    "start_time": "2023-12-02T05:19:05.324Z"
   },
   {
    "duration": 15,
    "start_time": "2023-12-02T05:19:05.341Z"
   },
   {
    "duration": 2131,
    "start_time": "2023-12-02T05:19:05.357Z"
   },
   {
    "duration": 14,
    "start_time": "2023-12-02T05:19:07.490Z"
   },
   {
    "duration": 325,
    "start_time": "2023-12-02T05:19:50.175Z"
   },
   {
    "duration": 3,
    "start_time": "2023-12-02T05:20:15.265Z"
   },
   {
    "duration": 4463,
    "start_time": "2023-12-02T05:20:15.985Z"
   },
   {
    "duration": 878,
    "start_time": "2023-12-02T05:20:20.450Z"
   },
   {
    "duration": 13,
    "start_time": "2023-12-02T05:20:21.330Z"
   },
   {
    "duration": 13,
    "start_time": "2023-12-02T05:20:21.345Z"
   },
   {
    "duration": 2085,
    "start_time": "2023-12-02T05:20:21.359Z"
   },
   {
    "duration": 2,
    "start_time": "2023-12-02T05:20:30.508Z"
   },
   {
    "duration": 528,
    "start_time": "2023-12-02T05:20:31.428Z"
   },
   {
    "duration": 15,
    "start_time": "2023-12-02T05:20:35.913Z"
   },
   {
    "duration": 341,
    "start_time": "2023-12-02T05:20:48.729Z"
   },
   {
    "duration": 27,
    "start_time": "2023-12-02T05:21:14.045Z"
   },
   {
    "duration": 3,
    "start_time": "2023-12-02T05:27:57.348Z"
   },
   {
    "duration": 4397,
    "start_time": "2023-12-02T05:27:57.944Z"
   },
   {
    "duration": 864,
    "start_time": "2023-12-02T05:28:02.343Z"
   },
   {
    "duration": 8,
    "start_time": "2023-12-02T05:28:03.208Z"
   },
   {
    "duration": 27,
    "start_time": "2023-12-02T05:28:03.217Z"
   },
   {
    "duration": 2,
    "start_time": "2023-12-02T05:28:06.837Z"
   },
   {
    "duration": 2,
    "start_time": "2023-12-02T05:28:07.961Z"
   },
   {
    "duration": 849,
    "start_time": "2023-12-02T05:28:10.310Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-02T05:28:11.161Z"
   },
   {
    "duration": 2120,
    "start_time": "2023-12-02T05:28:28.484Z"
   },
   {
    "duration": 111,
    "start_time": "2023-12-02T05:29:04.530Z"
   },
   {
    "duration": 1728,
    "start_time": "2023-12-02T05:29:11.947Z"
   },
   {
    "duration": 20,
    "start_time": "2023-12-02T05:31:57.928Z"
   },
   {
    "duration": 3,
    "start_time": "2023-12-02T05:32:25.496Z"
   },
   {
    "duration": 4523,
    "start_time": "2023-12-02T05:32:26.187Z"
   },
   {
    "duration": 930,
    "start_time": "2023-12-02T05:32:30.712Z"
   },
   {
    "duration": 8,
    "start_time": "2023-12-02T05:32:33.790Z"
   },
   {
    "duration": 14,
    "start_time": "2023-12-02T05:32:38.509Z"
   },
   {
    "duration": 2,
    "start_time": "2023-12-02T05:32:40.763Z"
   },
   {
    "duration": 2,
    "start_time": "2023-12-02T05:32:41.420Z"
   },
   {
    "duration": 4,
    "start_time": "2023-12-02T05:32:43.522Z"
   },
   {
    "duration": 7399,
    "start_time": "2023-12-02T05:33:25.665Z"
   },
   {
    "duration": 6,
    "start_time": "2023-12-02T05:35:59.584Z"
   },
   {
    "duration": 60,
    "start_time": "2023-12-02T05:36:01.712Z"
   },
   {
    "duration": 472,
    "start_time": "2023-12-02T05:38:58.169Z"
   },
   {
    "duration": 900,
    "start_time": "2023-12-02T05:39:24.687Z"
   },
   {
    "duration": 1843,
    "start_time": "2023-12-02T05:40:03.964Z"
   },
   {
    "duration": 3,
    "start_time": "2023-12-02T05:42:11.691Z"
   },
   {
    "duration": 4708,
    "start_time": "2023-12-02T05:42:11.886Z"
   },
   {
    "duration": 2276,
    "start_time": "2023-12-02T05:42:16.596Z"
   },
   {
    "duration": 7,
    "start_time": "2023-12-02T05:42:18.874Z"
   },
   {
    "duration": 14,
    "start_time": "2023-12-02T05:42:18.883Z"
   },
   {
    "duration": 8,
    "start_time": "2023-12-02T05:42:18.898Z"
   },
   {
    "duration": 25,
    "start_time": "2023-12-02T05:42:18.907Z"
   },
   {
    "duration": 7627,
    "start_time": "2023-12-02T05:42:18.934Z"
   },
   {
    "duration": 4,
    "start_time": "2023-12-02T05:42:26.563Z"
   },
   {
    "duration": 32,
    "start_time": "2023-12-02T05:42:26.569Z"
   },
   {
    "duration": 2270,
    "start_time": "2023-12-02T05:42:31.374Z"
   },
   {
    "duration": 955,
    "start_time": "2023-12-02T05:43:07.397Z"
   },
   {
    "duration": 3,
    "start_time": "2023-12-02T05:47:00.156Z"
   },
   {
    "duration": 4656,
    "start_time": "2023-12-02T05:47:00.161Z"
   },
   {
    "duration": 2265,
    "start_time": "2023-12-02T05:47:04.818Z"
   },
   {
    "duration": 8,
    "start_time": "2023-12-02T05:47:07.085Z"
   },
   {
    "duration": 22,
    "start_time": "2023-12-02T05:47:07.096Z"
   },
   {
    "duration": 25,
    "start_time": "2023-12-02T05:47:07.120Z"
   },
   {
    "duration": 15,
    "start_time": "2023-12-02T05:47:07.147Z"
   },
   {
    "duration": 7498,
    "start_time": "2023-12-02T05:47:07.163Z"
   },
   {
    "duration": 5,
    "start_time": "2023-12-02T05:47:14.663Z"
   },
   {
    "duration": 46,
    "start_time": "2023-12-02T05:47:14.670Z"
   },
   {
    "duration": 2197,
    "start_time": "2023-12-02T05:47:14.718Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-02T05:47:16.916Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-02T05:47:16.917Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-02T05:47:16.918Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-02T05:47:16.919Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-02T05:47:16.920Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-02T05:47:16.921Z"
   },
   {
    "duration": 3,
    "start_time": "2023-12-02T05:50:00.558Z"
   },
   {
    "duration": 4792,
    "start_time": "2023-12-02T05:50:00.714Z"
   },
   {
    "duration": 894,
    "start_time": "2023-12-02T05:50:05.508Z"
   },
   {
    "duration": 8,
    "start_time": "2023-12-02T05:50:06.403Z"
   },
   {
    "duration": 14,
    "start_time": "2023-12-02T05:50:06.412Z"
   },
   {
    "duration": 15,
    "start_time": "2023-12-02T05:50:06.427Z"
   },
   {
    "duration": 2,
    "start_time": "2023-12-02T05:50:06.444Z"
   },
   {
    "duration": 7601,
    "start_time": "2023-12-02T05:50:06.490Z"
   },
   {
    "duration": 10,
    "start_time": "2023-12-02T05:50:17.519Z"
   },
   {
    "duration": 26,
    "start_time": "2023-12-02T05:50:32.307Z"
   },
   {
    "duration": 1384,
    "start_time": "2023-12-02T05:50:57.825Z"
   },
   {
    "duration": 32,
    "start_time": "2023-12-02T05:51:27.264Z"
   },
   {
    "duration": 1775,
    "start_time": "2023-12-02T05:51:32.479Z"
   },
   {
    "duration": 4,
    "start_time": "2023-12-02T05:52:11.364Z"
   },
   {
    "duration": 4733,
    "start_time": "2023-12-02T05:52:11.370Z"
   },
   {
    "duration": 2266,
    "start_time": "2023-12-02T05:52:16.104Z"
   },
   {
    "duration": 9,
    "start_time": "2023-12-02T05:52:18.372Z"
   },
   {
    "duration": 16,
    "start_time": "2023-12-02T05:52:18.384Z"
   },
   {
    "duration": 5,
    "start_time": "2023-12-02T05:52:18.402Z"
   },
   {
    "duration": 10,
    "start_time": "2023-12-02T05:52:18.409Z"
   },
   {
    "duration": 7406,
    "start_time": "2023-12-02T05:52:18.421Z"
   },
   {
    "duration": 19,
    "start_time": "2023-12-02T05:52:25.828Z"
   },
   {
    "duration": 47,
    "start_time": "2023-12-02T05:52:25.849Z"
   },
   {
    "duration": 2234,
    "start_time": "2023-12-02T05:52:25.898Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-02T05:52:28.134Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-02T05:52:28.135Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-02T05:52:28.136Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-02T05:52:28.137Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-02T05:52:28.142Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-02T05:52:28.143Z"
   },
   {
    "duration": 3,
    "start_time": "2023-12-02T05:53:05.212Z"
   },
   {
    "duration": 4701,
    "start_time": "2023-12-02T05:53:05.217Z"
   },
   {
    "duration": 2264,
    "start_time": "2023-12-02T05:53:09.920Z"
   },
   {
    "duration": 9,
    "start_time": "2023-12-02T05:53:12.186Z"
   },
   {
    "duration": 27,
    "start_time": "2023-12-02T05:53:12.197Z"
   },
   {
    "duration": 4,
    "start_time": "2023-12-02T05:53:12.227Z"
   },
   {
    "duration": 14,
    "start_time": "2023-12-02T05:53:12.233Z"
   },
   {
    "duration": 7491,
    "start_time": "2023-12-02T05:53:12.249Z"
   },
   {
    "duration": 15,
    "start_time": "2023-12-02T05:53:19.743Z"
   },
   {
    "duration": 34,
    "start_time": "2023-12-02T05:53:19.761Z"
   },
   {
    "duration": 2165,
    "start_time": "2023-12-02T05:53:19.797Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-02T05:53:21.964Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-02T05:53:21.965Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-02T05:53:21.966Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-02T05:53:21.967Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-02T05:53:21.967Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-02T05:53:21.968Z"
   },
   {
    "duration": 23,
    "start_time": "2023-12-02T06:10:27.591Z"
   },
   {
    "duration": 18,
    "start_time": "2023-12-02T06:10:43.647Z"
   },
   {
    "duration": 19,
    "start_time": "2023-12-02T06:11:08.411Z"
   },
   {
    "duration": 4,
    "start_time": "2023-12-02T06:11:23.255Z"
   },
   {
    "duration": 4707,
    "start_time": "2023-12-02T06:11:23.806Z"
   },
   {
    "duration": 858,
    "start_time": "2023-12-02T06:11:28.515Z"
   },
   {
    "duration": 7,
    "start_time": "2023-12-02T06:11:29.375Z"
   },
   {
    "duration": 14,
    "start_time": "2023-12-02T06:11:31.641Z"
   },
   {
    "duration": 2,
    "start_time": "2023-12-02T06:11:32.457Z"
   },
   {
    "duration": 2,
    "start_time": "2023-12-02T06:11:33.149Z"
   },
   {
    "duration": 7181,
    "start_time": "2023-12-02T06:11:33.527Z"
   },
   {
    "duration": 10,
    "start_time": "2023-12-02T06:11:40.710Z"
   },
   {
    "duration": 38,
    "start_time": "2023-12-02T06:11:40.721Z"
   },
   {
    "duration": 529,
    "start_time": "2023-12-02T06:11:40.761Z"
   },
   {
    "duration": 16,
    "start_time": "2023-12-02T06:11:46.178Z"
   },
   {
    "duration": 19,
    "start_time": "2023-12-02T06:13:59.723Z"
   },
   {
    "duration": 20,
    "start_time": "2023-12-02T06:14:10.595Z"
   },
   {
    "duration": 3,
    "start_time": "2023-12-02T06:15:39.282Z"
   },
   {
    "duration": 4481,
    "start_time": "2023-12-02T06:15:39.287Z"
   },
   {
    "duration": 862,
    "start_time": "2023-12-02T06:15:43.769Z"
   },
   {
    "duration": 12,
    "start_time": "2023-12-02T06:15:44.632Z"
   },
   {
    "duration": 20,
    "start_time": "2023-12-02T06:15:44.645Z"
   },
   {
    "duration": 5,
    "start_time": "2023-12-02T06:15:44.667Z"
   },
   {
    "duration": 4,
    "start_time": "2023-12-02T06:15:44.674Z"
   },
   {
    "duration": 7231,
    "start_time": "2023-12-02T06:15:44.680Z"
   },
   {
    "duration": 7,
    "start_time": "2023-12-02T06:15:51.913Z"
   },
   {
    "duration": 50,
    "start_time": "2023-12-02T06:15:51.922Z"
   },
   {
    "duration": 2270,
    "start_time": "2023-12-02T06:15:51.974Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-02T06:15:54.246Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-02T06:15:54.247Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-02T06:15:54.248Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-02T06:15:54.249Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-02T06:15:54.250Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-02T06:15:54.251Z"
   },
   {
    "duration": 1300,
    "start_time": "2023-12-02T06:17:14.146Z"
   },
   {
    "duration": 3,
    "start_time": "2023-12-02T06:17:54.575Z"
   },
   {
    "duration": 4490,
    "start_time": "2023-12-02T06:17:54.579Z"
   },
   {
    "duration": 2257,
    "start_time": "2023-12-02T06:17:59.071Z"
   },
   {
    "duration": 7,
    "start_time": "2023-12-02T06:18:01.330Z"
   },
   {
    "duration": 44,
    "start_time": "2023-12-02T06:18:01.339Z"
   },
   {
    "duration": 32,
    "start_time": "2023-12-02T06:18:01.385Z"
   },
   {
    "duration": 23,
    "start_time": "2023-12-02T06:18:01.419Z"
   },
   {
    "duration": 7410,
    "start_time": "2023-12-02T06:18:01.444Z"
   },
   {
    "duration": 9,
    "start_time": "2023-12-02T06:18:08.856Z"
   },
   {
    "duration": 30,
    "start_time": "2023-12-02T06:18:08.867Z"
   },
   {
    "duration": 11800,
    "start_time": "2023-12-02T06:18:08.899Z"
   },
   {
    "duration": 337,
    "start_time": "2023-12-02T06:18:20.701Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-02T06:18:21.041Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-02T06:18:21.043Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-02T06:18:21.043Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-02T06:18:21.044Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-02T06:18:21.045Z"
   },
   {
    "duration": 4,
    "start_time": "2023-12-02T06:18:36.182Z"
   },
   {
    "duration": 19,
    "start_time": "2023-12-02T06:19:12.465Z"
   },
   {
    "duration": 18,
    "start_time": "2023-12-02T06:21:50.142Z"
   },
   {
    "duration": 104765,
    "start_time": "2023-12-02T06:21:59.880Z"
   },
   {
    "duration": 15,
    "start_time": "2023-12-02T06:27:57.288Z"
   },
   {
    "duration": 16,
    "start_time": "2023-12-02T06:28:37.816Z"
   },
   {
    "duration": 20,
    "start_time": "2023-12-02T06:28:44.423Z"
   },
   {
    "duration": 49417,
    "start_time": "2023-12-02T06:29:34.333Z"
   },
   {
    "duration": 105988,
    "start_time": "2023-12-02T06:36:50.863Z"
   },
   {
    "duration": 52897,
    "start_time": "2023-12-02T06:38:36.853Z"
   },
   {
    "duration": 3,
    "start_time": "2023-12-04T14:48:37.989Z"
   },
   {
    "duration": 4825,
    "start_time": "2023-12-04T14:48:37.997Z"
   },
   {
    "duration": 2470,
    "start_time": "2023-12-04T14:48:42.823Z"
   },
   {
    "duration": 7,
    "start_time": "2023-12-04T14:48:45.294Z"
   },
   {
    "duration": 21,
    "start_time": "2023-12-04T14:48:45.303Z"
   },
   {
    "duration": 3,
    "start_time": "2023-12-04T14:48:45.325Z"
   },
   {
    "duration": 17,
    "start_time": "2023-12-04T14:48:45.330Z"
   },
   {
    "duration": 8450,
    "start_time": "2023-12-04T14:48:45.348Z"
   },
   {
    "duration": 8,
    "start_time": "2023-12-04T14:48:53.800Z"
   },
   {
    "duration": 32,
    "start_time": "2023-12-04T14:48:53.810Z"
   },
   {
    "duration": 12584,
    "start_time": "2023-12-04T14:48:53.853Z"
   },
   {
    "duration": 109218,
    "start_time": "2023-12-04T14:49:06.439Z"
   },
   {
    "duration": 54898,
    "start_time": "2023-12-04T14:50:55.658Z"
   },
   {
    "duration": 77799,
    "start_time": "2023-12-04T14:51:50.561Z"
   },
   {
    "duration": 364,
    "start_time": "2023-12-04T15:05:38.923Z"
   },
   {
    "duration": 23,
    "start_time": "2023-12-04T15:07:16.451Z"
   },
   {
    "duration": 23,
    "start_time": "2023-12-04T15:07:19.758Z"
   },
   {
    "duration": 35,
    "start_time": "2023-12-04T15:07:37.200Z"
   },
   {
    "duration": 17,
    "start_time": "2023-12-04T15:08:13.571Z"
   },
   {
    "duration": 11027,
    "start_time": "2023-12-04T15:09:45.269Z"
   },
   {
    "duration": 52348,
    "start_time": "2023-12-04T15:12:12.684Z"
   },
   {
    "duration": 19,
    "start_time": "2023-12-04T15:13:35.311Z"
   },
   {
    "duration": 5377,
    "start_time": "2023-12-04T15:14:01.300Z"
   },
   {
    "duration": 130427,
    "start_time": "2023-12-04T15:14:16.396Z"
   },
   {
    "duration": 18,
    "start_time": "2023-12-04T15:19:46.367Z"
   },
   {
    "duration": 18,
    "start_time": "2023-12-04T15:20:27.875Z"
   },
   {
    "duration": 8079,
    "start_time": "2023-12-04T15:21:27.577Z"
   },
   {
    "duration": 20,
    "start_time": "2023-12-04T15:21:35.658Z"
   },
   {
    "duration": 7962,
    "start_time": "2023-12-04T15:23:43.043Z"
   },
   {
    "duration": 3,
    "start_time": "2023-12-04T15:47:52.831Z"
   },
   {
    "duration": 4589,
    "start_time": "2023-12-04T15:47:52.836Z"
   },
   {
    "duration": 886,
    "start_time": "2023-12-04T15:47:57.427Z"
   },
   {
    "duration": 7,
    "start_time": "2023-12-04T15:47:58.314Z"
   },
   {
    "duration": 31,
    "start_time": "2023-12-04T15:47:58.323Z"
   },
   {
    "duration": 6,
    "start_time": "2023-12-04T15:47:58.363Z"
   },
   {
    "duration": 3,
    "start_time": "2023-12-04T15:47:58.370Z"
   },
   {
    "duration": 7752,
    "start_time": "2023-12-04T15:47:58.374Z"
   },
   {
    "duration": 7,
    "start_time": "2023-12-04T15:48:06.128Z"
   },
   {
    "duration": 57,
    "start_time": "2023-12-04T15:48:06.137Z"
   },
   {
    "duration": 14392,
    "start_time": "2023-12-04T15:48:06.195Z"
   },
   {
    "duration": 106582,
    "start_time": "2023-12-04T15:48:20.588Z"
   },
   {
    "duration": 53395,
    "start_time": "2023-12-04T15:50:07.173Z"
   },
   {
    "duration": 75785,
    "start_time": "2023-12-04T15:51:00.570Z"
   },
   {
    "duration": 136830,
    "start_time": "2023-12-04T15:52:16.356Z"
   },
   {
    "duration": 5344,
    "start_time": "2023-12-04T15:54:33.187Z"
   },
   {
    "duration": 7915,
    "start_time": "2023-12-04T15:54:38.533Z"
   },
   {
    "duration": 342,
    "start_time": "2023-12-04T15:54:46.455Z"
   },
   {
    "duration": 34035,
    "start_time": "2023-12-04T15:59:33.992Z"
   },
   {
    "duration": 24,
    "start_time": "2023-12-04T16:00:33.370Z"
   },
   {
    "duration": 19,
    "start_time": "2023-12-04T16:00:44.824Z"
   },
   {
    "duration": 36733,
    "start_time": "2023-12-04T16:01:40.565Z"
   },
   {
    "duration": 16,
    "start_time": "2023-12-04T16:02:20.977Z"
   },
   {
    "duration": 34962,
    "start_time": "2023-12-04T16:02:31.446Z"
   },
   {
    "duration": 34127,
    "start_time": "2023-12-04T16:03:12.690Z"
   },
   {
    "duration": 768,
    "start_time": "2023-12-04T16:04:24.335Z"
   },
   {
    "duration": 6248,
    "start_time": "2023-12-04T16:06:40.734Z"
   },
   {
    "duration": 3,
    "start_time": "2023-12-04T16:13:45.697Z"
   },
   {
    "duration": 4510,
    "start_time": "2023-12-04T16:13:45.703Z"
   },
   {
    "duration": 834,
    "start_time": "2023-12-04T16:13:50.215Z"
   },
   {
    "duration": 11,
    "start_time": "2023-12-04T16:13:51.051Z"
   },
   {
    "duration": 22,
    "start_time": "2023-12-04T16:13:51.064Z"
   },
   {
    "duration": 13,
    "start_time": "2023-12-04T16:13:51.088Z"
   },
   {
    "duration": 5,
    "start_time": "2023-12-04T16:13:51.102Z"
   },
   {
    "duration": 7778,
    "start_time": "2023-12-04T16:13:51.108Z"
   },
   {
    "duration": 7,
    "start_time": "2023-12-04T16:13:58.887Z"
   },
   {
    "duration": 28,
    "start_time": "2023-12-04T16:13:58.896Z"
   },
   {
    "duration": 12898,
    "start_time": "2023-12-04T16:13:58.926Z"
   },
   {
    "duration": 113863,
    "start_time": "2023-12-04T16:14:11.826Z"
   },
   {
    "duration": 53262,
    "start_time": "2023-12-04T16:16:05.691Z"
   },
   {
    "duration": 129352,
    "start_time": "2023-12-04T16:16:58.955Z"
   },
   {
    "duration": 5293,
    "start_time": "2023-12-04T16:19:08.308Z"
   },
   {
    "duration": 33355,
    "start_time": "2023-12-04T16:19:13.602Z"
   },
   {
    "duration": 803,
    "start_time": "2023-12-04T16:19:46.965Z"
   },
   {
    "duration": 3,
    "start_time": "2023-12-04T16:30:12.277Z"
   },
   {
    "duration": 4293,
    "start_time": "2023-12-04T16:30:12.282Z"
   },
   {
    "duration": 852,
    "start_time": "2023-12-04T16:30:16.577Z"
   },
   {
    "duration": 7,
    "start_time": "2023-12-04T16:30:17.431Z"
   },
   {
    "duration": 22,
    "start_time": "2023-12-04T16:30:17.451Z"
   },
   {
    "duration": 2,
    "start_time": "2023-12-04T16:30:17.474Z"
   },
   {
    "duration": 5,
    "start_time": "2023-12-04T16:30:17.477Z"
   },
   {
    "duration": 7565,
    "start_time": "2023-12-04T16:30:17.483Z"
   },
   {
    "duration": 15,
    "start_time": "2023-12-04T16:30:25.055Z"
   },
   {
    "duration": 37,
    "start_time": "2023-12-04T16:30:25.071Z"
   },
   {
    "duration": 12475,
    "start_time": "2023-12-04T16:30:25.109Z"
   },
   {
    "duration": 2,
    "start_time": "2023-12-04T16:30:37.586Z"
   },
   {
    "duration": 5,
    "start_time": "2023-12-04T16:30:37.589Z"
   },
   {
    "duration": 2,
    "start_time": "2023-12-04T16:30:37.596Z"
   },
   {
    "duration": 8,
    "start_time": "2023-12-04T16:30:37.599Z"
   },
   {
    "duration": 4,
    "start_time": "2023-12-04T16:30:37.608Z"
   },
   {
    "duration": 7,
    "start_time": "2023-12-04T16:30:37.613Z"
   },
   {
    "duration": 354,
    "start_time": "2023-12-04T16:30:37.621Z"
   },
   {
    "duration": 2,
    "start_time": "2023-12-04T16:31:32.675Z"
   },
   {
    "duration": 4515,
    "start_time": "2023-12-04T16:31:32.679Z"
   },
   {
    "duration": 870,
    "start_time": "2023-12-04T16:31:37.196Z"
   },
   {
    "duration": 9,
    "start_time": "2023-12-04T16:31:38.070Z"
   },
   {
    "duration": 15,
    "start_time": "2023-12-04T16:31:38.081Z"
   },
   {
    "duration": 3,
    "start_time": "2023-12-04T16:31:38.098Z"
   },
   {
    "duration": 3,
    "start_time": "2023-12-04T16:31:38.102Z"
   },
   {
    "duration": 7837,
    "start_time": "2023-12-04T16:31:38.106Z"
   },
   {
    "duration": 21,
    "start_time": "2023-12-04T16:31:45.944Z"
   },
   {
    "duration": 26,
    "start_time": "2023-12-04T16:31:45.967Z"
   },
   {
    "duration": 11836,
    "start_time": "2023-12-04T16:31:45.994Z"
   },
   {
    "duration": 2,
    "start_time": "2023-12-04T16:31:57.832Z"
   },
   {
    "duration": 6,
    "start_time": "2023-12-04T16:31:57.835Z"
   },
   {
    "duration": 10,
    "start_time": "2023-12-04T16:31:57.843Z"
   },
   {
    "duration": 4,
    "start_time": "2023-12-04T16:31:57.855Z"
   },
   {
    "duration": 9,
    "start_time": "2023-12-04T16:31:57.861Z"
   },
   {
    "duration": 7,
    "start_time": "2023-12-04T16:31:57.871Z"
   },
   {
    "duration": 339,
    "start_time": "2023-12-04T16:31:57.879Z"
   },
   {
    "duration": 15,
    "start_time": "2023-12-04T16:35:34.582Z"
   },
   {
    "duration": 8,
    "start_time": "2023-12-04T16:36:17.059Z"
   },
   {
    "duration": 4581,
    "start_time": "2023-12-04T16:36:17.068Z"
   },
   {
    "duration": 862,
    "start_time": "2023-12-04T16:36:21.651Z"
   },
   {
    "duration": 7,
    "start_time": "2023-12-04T16:36:22.516Z"
   },
   {
    "duration": 12,
    "start_time": "2023-12-04T16:36:22.524Z"
   },
   {
    "duration": 14,
    "start_time": "2023-12-04T16:36:22.537Z"
   },
   {
    "duration": 11,
    "start_time": "2023-12-04T16:36:22.557Z"
   },
   {
    "duration": 7667,
    "start_time": "2023-12-04T16:36:22.569Z"
   },
   {
    "duration": 9,
    "start_time": "2023-12-04T16:36:30.237Z"
   },
   {
    "duration": 41,
    "start_time": "2023-12-04T16:36:30.255Z"
   },
   {
    "duration": 12188,
    "start_time": "2023-12-04T16:36:30.297Z"
   },
   {
    "duration": 3,
    "start_time": "2023-12-04T16:36:42.486Z"
   },
   {
    "duration": 4,
    "start_time": "2023-12-04T16:36:42.490Z"
   },
   {
    "duration": 23,
    "start_time": "2023-12-04T16:36:42.496Z"
   },
   {
    "duration": 4,
    "start_time": "2023-12-04T16:36:42.520Z"
   },
   {
    "duration": 11,
    "start_time": "2023-12-04T16:36:42.525Z"
   },
   {
    "duration": 9,
    "start_time": "2023-12-04T16:36:42.537Z"
   },
   {
    "duration": 3,
    "start_time": "2023-12-04T16:39:03.023Z"
   },
   {
    "duration": 4386,
    "start_time": "2023-12-04T16:39:03.029Z"
   },
   {
    "duration": 858,
    "start_time": "2023-12-04T16:39:07.417Z"
   },
   {
    "duration": 7,
    "start_time": "2023-12-04T16:39:08.276Z"
   },
   {
    "duration": 30,
    "start_time": "2023-12-04T16:39:08.285Z"
   },
   {
    "duration": 26,
    "start_time": "2023-12-04T16:39:08.317Z"
   },
   {
    "duration": 25,
    "start_time": "2023-12-04T16:39:08.345Z"
   },
   {
    "duration": 7729,
    "start_time": "2023-12-04T16:39:08.371Z"
   },
   {
    "duration": 8,
    "start_time": "2023-12-04T16:39:16.101Z"
   },
   {
    "duration": 30,
    "start_time": "2023-12-04T16:39:16.111Z"
   },
   {
    "duration": 12147,
    "start_time": "2023-12-04T16:39:16.153Z"
   },
   {
    "duration": 3,
    "start_time": "2023-12-04T16:39:28.302Z"
   },
   {
    "duration": 4,
    "start_time": "2023-12-04T16:39:28.306Z"
   },
   {
    "duration": 4,
    "start_time": "2023-12-04T16:39:28.311Z"
   },
   {
    "duration": 4,
    "start_time": "2023-12-04T16:39:28.316Z"
   },
   {
    "duration": 3,
    "start_time": "2023-12-04T16:39:28.322Z"
   },
   {
    "duration": 29,
    "start_time": "2023-12-04T16:39:28.327Z"
   },
   {
    "duration": 625002,
    "start_time": "2023-12-04T16:39:28.365Z"
   },
   {
    "duration": 353,
    "start_time": "2023-12-04T16:50:43.813Z"
   },
   {
    "duration": 390,
    "start_time": "2023-12-04T16:51:25.044Z"
   },
   {
    "duration": 3,
    "start_time": "2023-12-04T16:58:20.858Z"
   },
   {
    "duration": 4429,
    "start_time": "2023-12-04T16:58:22.376Z"
   },
   {
    "duration": 919,
    "start_time": "2023-12-04T16:58:26.807Z"
   },
   {
    "duration": 8,
    "start_time": "2023-12-04T16:58:28.889Z"
   },
   {
    "duration": 20,
    "start_time": "2023-12-04T16:58:32.242Z"
   },
   {
    "duration": 3,
    "start_time": "2023-12-04T16:58:32.906Z"
   },
   {
    "duration": 3,
    "start_time": "2023-12-04T16:58:34.025Z"
   },
   {
    "duration": 7555,
    "start_time": "2023-12-04T16:58:34.685Z"
   },
   {
    "duration": 9,
    "start_time": "2023-12-04T16:58:44.182Z"
   },
   {
    "duration": 29,
    "start_time": "2023-12-04T16:58:47.159Z"
   },
   {
    "duration": 59,
    "start_time": "2023-12-04T16:58:48.570Z"
   },
   {
    "duration": 3,
    "start_time": "2023-12-04T16:58:52.796Z"
   },
   {
    "duration": 4,
    "start_time": "2023-12-04T16:59:22.049Z"
   },
   {
    "duration": 4525,
    "start_time": "2023-12-04T16:59:22.058Z"
   },
   {
    "duration": 2284,
    "start_time": "2023-12-04T16:59:26.585Z"
   },
   {
    "duration": 7,
    "start_time": "2023-12-04T16:59:28.870Z"
   },
   {
    "duration": 14,
    "start_time": "2023-12-04T16:59:28.878Z"
   },
   {
    "duration": 8,
    "start_time": "2023-12-04T16:59:28.893Z"
   },
   {
    "duration": 19,
    "start_time": "2023-12-04T16:59:28.902Z"
   },
   {
    "duration": 7636,
    "start_time": "2023-12-04T16:59:28.922Z"
   },
   {
    "duration": 8,
    "start_time": "2023-12-04T16:59:36.560Z"
   },
   {
    "duration": 26,
    "start_time": "2023-12-04T16:59:36.570Z"
   },
   {
    "duration": 70,
    "start_time": "2023-12-04T16:59:36.599Z"
   },
   {
    "duration": 2,
    "start_time": "2023-12-04T16:59:36.671Z"
   },
   {
    "duration": 3,
    "start_time": "2023-12-04T17:02:00.515Z"
   },
   {
    "duration": 4583,
    "start_time": "2023-12-04T17:02:00.720Z"
   },
   {
    "duration": 2363,
    "start_time": "2023-12-04T17:02:05.305Z"
   },
   {
    "duration": 7,
    "start_time": "2023-12-04T17:02:09.708Z"
   },
   {
    "duration": 19,
    "start_time": "2023-12-04T17:02:12.163Z"
   },
   {
    "duration": 3,
    "start_time": "2023-12-04T17:02:13.442Z"
   },
   {
    "duration": 3,
    "start_time": "2023-12-04T17:02:14.348Z"
   },
   {
    "duration": 7569,
    "start_time": "2023-12-04T17:02:15.212Z"
   },
   {
    "duration": 11,
    "start_time": "2023-12-04T17:02:24.844Z"
   },
   {
    "duration": 30,
    "start_time": "2023-12-04T17:02:26.131Z"
   },
   {
    "duration": 32,
    "start_time": "2023-12-04T17:02:26.901Z"
   },
   {
    "duration": 3,
    "start_time": "2023-12-04T17:02:32.516Z"
   },
   {
    "duration": 555,
    "start_time": "2023-12-04T17:02:33.432Z"
   },
   {
    "duration": 4065,
    "start_time": "2023-12-04T17:03:07.232Z"
   },
   {
    "duration": 28,
    "start_time": "2023-12-04T17:03:44.004Z"
   },
   {
    "duration": 25,
    "start_time": "2023-12-04T17:04:47.045Z"
   },
   {
    "duration": 35792,
    "start_time": "2023-12-04T17:05:03.680Z"
   },
   {
    "duration": 3,
    "start_time": "2023-12-05T03:44:10.756Z"
   },
   {
    "duration": 4861,
    "start_time": "2023-12-05T03:44:10.761Z"
   },
   {
    "duration": 2374,
    "start_time": "2023-12-05T03:44:15.624Z"
   },
   {
    "duration": 7,
    "start_time": "2023-12-05T03:44:18.000Z"
   },
   {
    "duration": 18,
    "start_time": "2023-12-05T03:44:18.009Z"
   },
   {
    "duration": 2,
    "start_time": "2023-12-05T03:44:18.031Z"
   },
   {
    "duration": 16,
    "start_time": "2023-12-05T03:44:18.034Z"
   },
   {
    "duration": 7510,
    "start_time": "2023-12-05T03:44:18.051Z"
   },
   {
    "duration": 10,
    "start_time": "2023-12-05T03:44:25.563Z"
   },
   {
    "duration": 41,
    "start_time": "2023-12-05T03:44:25.575Z"
   },
   {
    "duration": 42,
    "start_time": "2023-12-05T03:44:25.618Z"
   },
   {
    "duration": 3,
    "start_time": "2023-12-05T03:44:25.662Z"
   },
   {
    "duration": 4086,
    "start_time": "2023-12-05T03:44:25.667Z"
   },
   {
    "duration": 3,
    "start_time": "2023-12-05T03:44:29.754Z"
   },
   {
    "duration": 3,
    "start_time": "2023-12-05T03:45:16.884Z"
   },
   {
    "duration": 4517,
    "start_time": "2023-12-05T03:45:18.063Z"
   },
   {
    "duration": 886,
    "start_time": "2023-12-05T03:45:22.582Z"
   },
   {
    "duration": 29,
    "start_time": "2023-12-05T03:45:39.551Z"
   },
   {
    "duration": 25,
    "start_time": "2023-12-05T03:46:39.804Z"
   },
   {
    "duration": 26,
    "start_time": "2023-12-05T03:46:45.073Z"
   },
   {
    "duration": 243,
    "start_time": "2023-12-05T03:47:09.610Z"
   },
   {
    "duration": 1286,
    "start_time": "2023-12-05T03:49:07.584Z"
   },
   {
    "duration": 406,
    "start_time": "2023-12-05T03:50:23.643Z"
   },
   {
    "duration": 357,
    "start_time": "2023-12-05T03:50:56.522Z"
   },
   {
    "duration": 315,
    "start_time": "2023-12-05T03:52:32.798Z"
   },
   {
    "duration": 294,
    "start_time": "2023-12-05T03:52:40.982Z"
   },
   {
    "duration": 301,
    "start_time": "2023-12-05T03:54:34.343Z"
   },
   {
    "duration": 362,
    "start_time": "2023-12-05T03:54:58.900Z"
   },
   {
    "duration": 356,
    "start_time": "2023-12-05T03:56:17.127Z"
   },
   {
    "duration": 78,
    "start_time": "2023-12-05T03:57:03.591Z"
   },
   {
    "duration": 381,
    "start_time": "2023-12-05T03:57:21.192Z"
   },
   {
    "duration": 381,
    "start_time": "2023-12-05T03:57:39.704Z"
   },
   {
    "duration": 364,
    "start_time": "2023-12-05T03:58:51.456Z"
   },
   {
    "duration": 362,
    "start_time": "2023-12-05T03:59:34.796Z"
   },
   {
    "duration": 371,
    "start_time": "2023-12-05T03:59:51.612Z"
   },
   {
    "duration": 377,
    "start_time": "2023-12-05T04:01:24.772Z"
   },
   {
    "duration": 388,
    "start_time": "2023-12-05T04:01:40.825Z"
   },
   {
    "duration": 362,
    "start_time": "2023-12-05T04:01:56.789Z"
   },
   {
    "duration": 380,
    "start_time": "2023-12-05T04:02:35.389Z"
   },
   {
    "duration": 380,
    "start_time": "2023-12-05T04:02:47.698Z"
   },
   {
    "duration": 6,
    "start_time": "2023-12-05T04:03:02.238Z"
   },
   {
    "duration": 15,
    "start_time": "2023-12-05T04:03:05.667Z"
   },
   {
    "duration": 2,
    "start_time": "2023-12-05T04:03:08.947Z"
   },
   {
    "duration": 2,
    "start_time": "2023-12-05T04:03:10.034Z"
   },
   {
    "duration": 7460,
    "start_time": "2023-12-05T04:03:11.410Z"
   },
   {
    "duration": 9,
    "start_time": "2023-12-05T04:03:22.690Z"
   },
   {
    "duration": 37,
    "start_time": "2023-12-05T04:03:56.125Z"
   },
   {
    "duration": 34,
    "start_time": "2023-12-05T04:04:12.348Z"
   },
   {
    "duration": 29,
    "start_time": "2023-12-05T04:10:34.057Z"
   },
   {
    "duration": 8,
    "start_time": "2023-12-05T04:12:07.652Z"
   },
   {
    "duration": 16,
    "start_time": "2023-12-05T04:12:33.132Z"
   },
   {
    "duration": 9,
    "start_time": "2023-12-05T04:12:57.087Z"
   },
   {
    "duration": 25,
    "start_time": "2023-12-05T04:13:38.928Z"
   },
   {
    "duration": 129,
    "start_time": "2023-12-05T04:14:01.287Z"
   },
   {
    "duration": 145,
    "start_time": "2023-12-05T04:14:31.162Z"
   },
   {
    "duration": 222,
    "start_time": "2023-12-05T04:18:23.891Z"
   },
   {
    "duration": 13435,
    "start_time": "2023-12-05T04:18:45.303Z"
   },
   {
    "duration": 6682,
    "start_time": "2023-12-05T04:19:42.959Z"
   },
   {
    "duration": 11,
    "start_time": "2023-12-05T04:20:26.652Z"
   },
   {
    "duration": 11,
    "start_time": "2023-12-05T04:20:46.514Z"
   },
   {
    "duration": 11,
    "start_time": "2023-12-05T04:20:54.774Z"
   },
   {
    "duration": 11,
    "start_time": "2023-12-05T04:21:19.973Z"
   },
   {
    "duration": 2145,
    "start_time": "2023-12-05T04:22:01.139Z"
   },
   {
    "duration": 23,
    "start_time": "2023-12-05T04:22:31.087Z"
   },
   {
    "duration": 3,
    "start_time": "2023-12-05T04:23:29.848Z"
   },
   {
    "duration": 4547,
    "start_time": "2023-12-05T04:23:30.044Z"
   },
   {
    "duration": 871,
    "start_time": "2023-12-05T04:23:34.593Z"
   },
   {
    "duration": 29,
    "start_time": "2023-12-05T04:23:37.875Z"
   },
   {
    "duration": 580,
    "start_time": "2023-12-05T04:23:38.938Z"
   },
   {
    "duration": 8,
    "start_time": "2023-12-05T04:23:41.976Z"
   },
   {
    "duration": 20,
    "start_time": "2023-12-05T04:23:43.255Z"
   },
   {
    "duration": 3,
    "start_time": "2023-12-05T04:23:43.999Z"
   },
   {
    "duration": 2,
    "start_time": "2023-12-05T04:23:45.135Z"
   },
   {
    "duration": 7266,
    "start_time": "2023-12-05T04:23:46.252Z"
   },
   {
    "duration": 9,
    "start_time": "2023-12-05T04:23:56.028Z"
   },
   {
    "duration": 29,
    "start_time": "2023-12-05T04:23:58.343Z"
   },
   {
    "duration": 33,
    "start_time": "2023-12-05T04:24:02.715Z"
   },
   {
    "duration": 7,
    "start_time": "2023-12-05T04:24:15.352Z"
   },
   {
    "duration": 10,
    "start_time": "2023-12-05T04:24:22.723Z"
   },
   {
    "duration": 126,
    "start_time": "2023-12-05T04:24:37.084Z"
   },
   {
    "duration": 13365,
    "start_time": "2023-12-05T04:24:40.411Z"
   },
   {
    "duration": 4,
    "start_time": "2023-12-05T04:25:42.896Z"
   },
   {
    "duration": 332,
    "start_time": "2023-12-05T04:27:00.388Z"
   },
   {
    "duration": 67899,
    "start_time": "2023-12-05T04:27:17.456Z"
   },
   {
    "duration": 23339,
    "start_time": "2023-12-05T04:29:49.015Z"
   },
   {
    "duration": 65078,
    "start_time": "2023-12-05T04:31:25.892Z"
   },
   {
    "duration": 124070,
    "start_time": "2023-12-05T04:35:01.025Z"
   },
   {
    "duration": 130063,
    "start_time": "2023-12-05T04:39:11.288Z"
   },
   {
    "duration": 10615,
    "start_time": "2023-12-05T04:41:45.076Z"
   },
   {
    "duration": 38722,
    "start_time": "2023-12-05T04:46:33.186Z"
   },
   {
    "duration": 3,
    "start_time": "2023-12-05T04:57:43.129Z"
   },
   {
    "duration": 4842,
    "start_time": "2023-12-05T04:57:43.137Z"
   },
   {
    "duration": 907,
    "start_time": "2023-12-05T04:57:47.982Z"
   },
   {
    "duration": 30,
    "start_time": "2023-12-05T04:57:48.890Z"
   },
   {
    "duration": 429,
    "start_time": "2023-12-05T04:57:48.922Z"
   },
   {
    "duration": 6,
    "start_time": "2023-12-05T04:57:49.353Z"
   },
   {
    "duration": 15,
    "start_time": "2023-12-05T04:57:49.360Z"
   },
   {
    "duration": 3,
    "start_time": "2023-12-05T04:57:49.376Z"
   },
   {
    "duration": 7420,
    "start_time": "2023-12-05T04:57:49.380Z"
   },
   {
    "duration": 10,
    "start_time": "2023-12-05T04:57:56.801Z"
   },
   {
    "duration": 40,
    "start_time": "2023-12-05T04:57:56.812Z"
   },
   {
    "duration": 32,
    "start_time": "2023-12-05T04:57:56.854Z"
   },
   {
    "duration": 378,
    "start_time": "2023-12-05T04:57:56.887Z"
   },
   {
    "duration": 13839,
    "start_time": "2023-12-05T04:57:57.267Z"
   },
   {
    "duration": 71256,
    "start_time": "2023-12-05T04:58:11.109Z"
   },
   {
    "duration": 67994,
    "start_time": "2023-12-05T04:59:22.366Z"
   },
   {
    "duration": 15988,
    "start_time": "2023-12-05T05:00:30.362Z"
   },
   {
    "duration": 128300,
    "start_time": "2023-12-05T05:00:46.351Z"
   },
   {
    "duration": 129679,
    "start_time": "2023-12-05T05:02:54.652Z"
   },
   {
    "duration": 11233,
    "start_time": "2023-12-05T05:05:04.333Z"
   },
   {
    "duration": 38810,
    "start_time": "2023-12-05T05:05:15.568Z"
   },
   {
    "duration": 350,
    "start_time": "2023-12-05T05:05:54.379Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-05T05:05:54.730Z"
   },
   {
    "duration": 20,
    "start_time": "2023-12-05T05:06:53.995Z"
   },
   {
    "duration": 4,
    "start_time": "2023-12-05T05:16:27.362Z"
   },
   {
    "duration": 4877,
    "start_time": "2023-12-05T05:16:27.370Z"
   },
   {
    "duration": 895,
    "start_time": "2023-12-05T05:16:32.249Z"
   },
   {
    "duration": 31,
    "start_time": "2023-12-05T05:16:33.146Z"
   },
   {
    "duration": 423,
    "start_time": "2023-12-05T05:16:33.180Z"
   },
   {
    "duration": 7,
    "start_time": "2023-12-05T05:16:33.605Z"
   },
   {
    "duration": 31,
    "start_time": "2023-12-05T05:16:33.613Z"
   },
   {
    "duration": 7,
    "start_time": "2023-12-05T05:16:33.646Z"
   },
   {
    "duration": 7415,
    "start_time": "2023-12-05T05:16:33.655Z"
   },
   {
    "duration": 16,
    "start_time": "2023-12-05T05:16:41.072Z"
   },
   {
    "duration": 52,
    "start_time": "2023-12-05T05:16:41.092Z"
   },
   {
    "duration": 46,
    "start_time": "2023-12-05T05:16:41.145Z"
   },
   {
    "duration": 373,
    "start_time": "2023-12-05T05:16:41.193Z"
   },
   {
    "duration": 14016,
    "start_time": "2023-12-05T05:16:41.568Z"
   },
   {
    "duration": 2,
    "start_time": "2023-12-05T05:16:55.586Z"
   },
   {
    "duration": 8,
    "start_time": "2023-12-05T05:16:55.590Z"
   },
   {
    "duration": 5,
    "start_time": "2023-12-05T05:16:55.600Z"
   },
   {
    "duration": 6,
    "start_time": "2023-12-05T05:16:55.606Z"
   },
   {
    "duration": 16,
    "start_time": "2023-12-05T05:16:55.614Z"
   },
   {
    "duration": 11,
    "start_time": "2023-12-05T05:16:55.632Z"
   },
   {
    "duration": 9,
    "start_time": "2023-12-05T05:16:55.645Z"
   },
   {
    "duration": 1039550,
    "start_time": "2023-12-05T05:16:55.655Z"
   },
   {
    "duration": 2,
    "start_time": "2023-12-05T05:34:15.207Z"
   },
   {
    "duration": 380,
    "start_time": "2023-12-05T05:41:30.331Z"
   },
   {
    "duration": 265959,
    "start_time": "2023-12-05T05:41:55.103Z"
   },
   {
    "duration": 542565,
    "start_time": "2023-12-05T05:49:50.597Z"
   },
   {
    "duration": 4,
    "start_time": "2023-12-05T06:17:12.245Z"
   },
   {
    "duration": 99,
    "start_time": "2023-12-05T06:30:27.801Z"
   },
   {
    "duration": 3,
    "start_time": "2023-12-05T06:39:46.471Z"
   },
   {
    "duration": 2261,
    "start_time": "2023-12-05T06:39:46.476Z"
   },
   {
    "duration": 874,
    "start_time": "2023-12-05T06:39:48.739Z"
   },
   {
    "duration": 37,
    "start_time": "2023-12-05T06:39:49.614Z"
   },
   {
    "duration": 432,
    "start_time": "2023-12-05T06:39:49.653Z"
   },
   {
    "duration": 5,
    "start_time": "2023-12-05T06:39:50.087Z"
   },
   {
    "duration": 16,
    "start_time": "2023-12-05T06:39:50.094Z"
   },
   {
    "duration": 19,
    "start_time": "2023-12-05T06:39:50.112Z"
   },
   {
    "duration": 7229,
    "start_time": "2023-12-05T06:39:50.133Z"
   },
   {
    "duration": 9,
    "start_time": "2023-12-05T06:39:57.363Z"
   },
   {
    "duration": 43,
    "start_time": "2023-12-05T06:39:57.374Z"
   },
   {
    "duration": 38,
    "start_time": "2023-12-05T06:39:57.419Z"
   },
   {
    "duration": 141,
    "start_time": "2023-12-05T06:39:57.458Z"
   },
   {
    "duration": 13760,
    "start_time": "2023-12-05T06:39:57.602Z"
   },
   {
    "duration": 69507,
    "start_time": "2023-12-05T06:40:11.363Z"
   },
   {
    "duration": 68192,
    "start_time": "2023-12-05T06:41:20.872Z"
   },
   {
    "duration": 11180,
    "start_time": "2023-12-05T06:42:29.066Z"
   },
   {
    "duration": 127356,
    "start_time": "2023-12-05T06:42:40.248Z"
   },
   {
    "duration": 138446,
    "start_time": "2023-12-05T06:44:47.605Z"
   },
   {
    "duration": 11404,
    "start_time": "2023-12-05T06:47:06.054Z"
   },
   {
    "duration": 41946,
    "start_time": "2023-12-05T06:47:17.460Z"
   },
   {
    "duration": 1059810,
    "start_time": "2023-12-05T06:47:59.408Z"
   },
   {
    "duration": 223211,
    "start_time": "2023-12-05T07:05:39.219Z"
   },
   {
    "duration": 841932,
    "start_time": "2023-12-05T07:09:22.431Z"
   },
   {
    "duration": 14500,
    "start_time": "2023-12-05T07:23:24.365Z"
   },
   {
    "duration": 3,
    "start_time": "2023-12-05T07:23:38.944Z"
   },
   {
    "duration": 93,
    "start_time": "2023-12-05T08:10:31.538Z"
   },
   {
    "duration": 142,
    "start_time": "2023-12-05T08:11:42.950Z"
   },
   {
    "duration": 15,
    "start_time": "2023-12-05T08:11:58.786Z"
   },
   {
    "duration": 6865,
    "start_time": "2023-12-05T08:13:18.879Z"
   },
   {
    "duration": 4,
    "start_time": "2023-12-05T08:14:59.826Z"
   },
   {
    "duration": 5,
    "start_time": "2023-12-05T08:15:06.767Z"
   },
   {
    "duration": 3,
    "start_time": "2023-12-05T08:15:30.575Z"
   },
   {
    "duration": 9,
    "start_time": "2023-12-05T08:15:51.894Z"
   },
   {
    "duration": 3,
    "start_time": "2023-12-05T08:16:53.024Z"
   },
   {
    "duration": 90,
    "start_time": "2023-12-05T08:16:53.173Z"
   },
   {
    "duration": 43,
    "start_time": "2023-12-05T08:16:53.348Z"
   },
   {
    "duration": 5,
    "start_time": "2023-12-05T08:16:53.532Z"
   },
   {
    "duration": 7,
    "start_time": "2023-12-05T08:16:53.721Z"
   },
   {
    "duration": 6,
    "start_time": "2023-12-05T08:16:54.072Z"
   },
   {
    "duration": 6,
    "start_time": "2023-12-05T08:16:54.420Z"
   },
   {
    "duration": 3,
    "start_time": "2023-12-05T08:16:54.592Z"
   },
   {
    "duration": 7,
    "start_time": "2023-12-05T08:16:54.772Z"
   },
   {
    "duration": 6,
    "start_time": "2023-12-05T08:16:54.948Z"
   },
   {
    "duration": 6,
    "start_time": "2023-12-05T08:16:55.177Z"
   },
   {
    "duration": 917,
    "start_time": "2023-12-05T08:16:55.880Z"
   },
   {
    "duration": 3,
    "start_time": "2023-12-05T08:17:20.804Z"
   },
   {
    "duration": 92,
    "start_time": "2023-12-05T08:17:21.847Z"
   },
   {
    "duration": 2278,
    "start_time": "2023-12-05T08:17:47.872Z"
   },
   {
    "duration": 898,
    "start_time": "2023-12-05T08:17:50.152Z"
   },
   {
    "duration": 34,
    "start_time": "2023-12-05T08:17:53.748Z"
   },
   {
    "duration": 413,
    "start_time": "2023-12-05T08:17:54.215Z"
   },
   {
    "duration": 6,
    "start_time": "2023-12-05T08:17:55.832Z"
   },
   {
    "duration": 13,
    "start_time": "2023-12-05T08:17:57.188Z"
   },
   {
    "duration": 2,
    "start_time": "2023-12-05T08:17:57.404Z"
   },
   {
    "duration": 7442,
    "start_time": "2023-12-05T08:17:57.635Z"
   },
   {
    "duration": 9,
    "start_time": "2023-12-05T08:18:05.079Z"
   },
   {
    "duration": 33,
    "start_time": "2023-12-05T08:18:05.089Z"
   },
   {
    "duration": 32,
    "start_time": "2023-12-05T08:18:08.283Z"
   },
   {
    "duration": 139,
    "start_time": "2023-12-05T08:18:09.895Z"
   },
   {
    "duration": 13913,
    "start_time": "2023-12-05T08:18:11.270Z"
   },
   {
    "duration": 72438,
    "start_time": "2023-12-05T08:18:33.112Z"
   },
   {
    "duration": 69513,
    "start_time": "2023-12-05T08:19:45.552Z"
   },
   {
    "duration": 10183,
    "start_time": "2023-12-05T08:20:55.066Z"
   },
   {
    "duration": 166,
    "start_time": "2023-12-05T08:25:16.250Z"
   },
   {
    "duration": 3,
    "start_time": "2023-12-05T08:25:33.057Z"
   },
   {
    "duration": 2265,
    "start_time": "2023-12-05T08:25:33.062Z"
   },
   {
    "duration": 886,
    "start_time": "2023-12-05T08:25:35.330Z"
   },
   {
    "duration": 37,
    "start_time": "2023-12-05T08:25:36.218Z"
   },
   {
    "duration": 439,
    "start_time": "2023-12-05T08:25:36.257Z"
   },
   {
    "duration": 6,
    "start_time": "2023-12-05T08:25:36.697Z"
   },
   {
    "duration": 15,
    "start_time": "2023-12-05T08:25:36.705Z"
   },
   {
    "duration": 2,
    "start_time": "2023-12-05T08:25:36.778Z"
   },
   {
    "duration": 7524,
    "start_time": "2023-12-05T08:25:38.122Z"
   },
   {
    "duration": 11,
    "start_time": "2023-12-05T08:25:45.648Z"
   },
   {
    "duration": 39,
    "start_time": "2023-12-05T08:25:45.661Z"
   },
   {
    "duration": 37,
    "start_time": "2023-12-05T08:25:49.649Z"
   },
   {
    "duration": 4,
    "start_time": "2023-12-05T08:29:42.794Z"
   },
   {
    "duration": 2504,
    "start_time": "2023-12-05T08:29:43.205Z"
   },
   {
    "duration": 881,
    "start_time": "2023-12-05T08:29:45.712Z"
   },
   {
    "duration": 32,
    "start_time": "2023-12-05T08:29:46.594Z"
   },
   {
    "duration": 432,
    "start_time": "2023-12-05T08:29:46.628Z"
   },
   {
    "duration": 7,
    "start_time": "2023-12-05T08:29:48.986Z"
   },
   {
    "duration": 14,
    "start_time": "2023-12-05T08:29:49.766Z"
   },
   {
    "duration": 2,
    "start_time": "2023-12-05T08:29:49.983Z"
   },
   {
    "duration": 7736,
    "start_time": "2023-12-05T08:29:51.143Z"
   },
   {
    "duration": 9,
    "start_time": "2023-12-05T08:29:59.979Z"
   },
   {
    "duration": 31,
    "start_time": "2023-12-05T08:30:00.738Z"
   },
   {
    "duration": 39,
    "start_time": "2023-12-05T08:30:02.946Z"
   },
   {
    "duration": 142,
    "start_time": "2023-12-05T08:30:11.267Z"
   },
   {
    "duration": 14558,
    "start_time": "2023-12-05T08:30:12.279Z"
   },
   {
    "duration": 72824,
    "start_time": "2023-12-05T08:30:42.635Z"
   },
   {
    "duration": 72993,
    "start_time": "2023-12-05T08:31:55.461Z"
   },
   {
    "duration": 33495,
    "start_time": "2023-12-05T08:33:08.456Z"
   },
   {
    "duration": 7616,
    "start_time": "2023-12-05T08:33:47.839Z"
   },
   {
    "duration": 57145,
    "start_time": "2023-12-05T08:34:55.408Z"
   },
   {
    "duration": 3,
    "start_time": "2023-12-05T08:36:30.838Z"
   },
   {
    "duration": 2761,
    "start_time": "2023-12-05T08:36:30.844Z"
   },
   {
    "duration": 948,
    "start_time": "2023-12-05T08:36:33.607Z"
   },
   {
    "duration": 34,
    "start_time": "2023-12-05T08:36:34.557Z"
   },
   {
    "duration": 452,
    "start_time": "2023-12-05T08:36:34.592Z"
   },
   {
    "duration": 6,
    "start_time": "2023-12-05T08:36:35.045Z"
   },
   {
    "duration": 13,
    "start_time": "2023-12-05T08:36:35.053Z"
   },
   {
    "duration": 3,
    "start_time": "2023-12-05T08:36:35.068Z"
   },
   {
    "duration": 7699,
    "start_time": "2023-12-05T08:36:35.073Z"
   },
   {
    "duration": 10,
    "start_time": "2023-12-05T08:36:42.774Z"
   },
   {
    "duration": 60,
    "start_time": "2023-12-05T08:36:42.787Z"
   },
   {
    "duration": 57,
    "start_time": "2023-12-05T08:36:42.849Z"
   },
   {
    "duration": 156,
    "start_time": "2023-12-05T08:36:42.907Z"
   },
   {
    "duration": 13986,
    "start_time": "2023-12-05T08:36:43.064Z"
   },
   {
    "duration": 74319,
    "start_time": "2023-12-05T08:36:57.053Z"
   },
   {
    "duration": 72481,
    "start_time": "2023-12-05T08:38:11.374Z"
   },
   {
    "duration": 34996,
    "start_time": "2023-12-05T08:39:23.857Z"
   },
   {
    "duration": 130832,
    "start_time": "2023-12-05T08:39:58.855Z"
   },
   {
    "duration": 132966,
    "start_time": "2023-12-05T08:42:09.689Z"
   },
   {
    "duration": 12310,
    "start_time": "2023-12-05T08:44:22.657Z"
   },
   {
    "duration": 38824,
    "start_time": "2023-12-05T08:44:34.969Z"
   },
   {
    "duration": 1013956,
    "start_time": "2023-12-05T08:45:13.795Z"
   },
   {
    "duration": 228235,
    "start_time": "2023-12-05T09:02:07.753Z"
   },
   {
    "duration": 1006168,
    "start_time": "2023-12-05T09:05:55.990Z"
   },
   {
    "duration": 44919,
    "start_time": "2023-12-05T09:22:42.159Z"
   },
   {
    "duration": 56330,
    "start_time": "2023-12-05T09:23:27.080Z"
   },
   {
    "duration": 56751,
    "start_time": "2023-12-05T09:24:46.003Z"
   },
   {
    "duration": 3,
    "start_time": "2023-12-05T09:31:07.508Z"
   },
   {
    "duration": 2508,
    "start_time": "2023-12-05T09:31:07.513Z"
   },
   {
    "duration": 1005,
    "start_time": "2023-12-05T09:31:10.022Z"
   },
   {
    "duration": 41,
    "start_time": "2023-12-05T09:31:11.029Z"
   },
   {
    "duration": 456,
    "start_time": "2023-12-05T09:31:11.072Z"
   },
   {
    "duration": 6,
    "start_time": "2023-12-05T09:31:11.530Z"
   },
   {
    "duration": 25,
    "start_time": "2023-12-05T09:31:11.542Z"
   },
   {
    "duration": 6,
    "start_time": "2023-12-05T09:31:11.569Z"
   },
   {
    "duration": 8388,
    "start_time": "2023-12-05T09:31:11.577Z"
   },
   {
    "duration": 10,
    "start_time": "2023-12-05T09:31:19.969Z"
   },
   {
    "duration": 32,
    "start_time": "2023-12-05T09:31:19.981Z"
   },
   {
    "duration": 67,
    "start_time": "2023-12-05T09:31:20.015Z"
   },
   {
    "duration": 174,
    "start_time": "2023-12-05T09:31:20.084Z"
   },
   {
    "duration": 15440,
    "start_time": "2023-12-05T09:31:20.260Z"
   },
   {
    "duration": 2,
    "start_time": "2023-12-05T09:31:35.702Z"
   },
   {
    "duration": 5,
    "start_time": "2023-12-05T09:31:35.705Z"
   },
   {
    "duration": 5,
    "start_time": "2023-12-05T09:31:35.711Z"
   },
   {
    "duration": 4,
    "start_time": "2023-12-05T09:31:35.718Z"
   },
   {
    "duration": 6,
    "start_time": "2023-12-05T09:31:35.724Z"
   },
   {
    "duration": 6,
    "start_time": "2023-12-05T09:31:35.731Z"
   },
   {
    "duration": 6,
    "start_time": "2023-12-05T09:31:35.755Z"
   },
   {
    "duration": 3,
    "start_time": "2023-12-05T09:31:35.763Z"
   },
   {
    "duration": 227568,
    "start_time": "2023-12-05T09:31:35.768Z"
   },
   {
    "duration": 3,
    "start_time": "2023-12-05T09:35:23.338Z"
   },
   {
    "duration": 11,
    "start_time": "2023-12-05T09:35:23.354Z"
   },
   {
    "duration": 5,
    "start_time": "2023-12-05T09:35:23.367Z"
   },
   {
    "duration": 158485,
    "start_time": "2023-12-05T09:35:23.373Z"
   },
   {
    "duration": 693138,
    "start_time": "2023-12-05T09:38:47.420Z"
   },
   {
    "duration": 83,
    "start_time": "2023-12-05T12:59:16.180Z"
   },
   {
    "duration": 2363,
    "start_time": "2023-12-05T13:03:11.709Z"
   },
   {
    "duration": 899,
    "start_time": "2023-12-05T13:03:14.074Z"
   },
   {
    "duration": 34,
    "start_time": "2023-12-05T13:03:14.974Z"
   },
   {
    "duration": 473,
    "start_time": "2023-12-05T13:03:15.010Z"
   },
   {
    "duration": 5,
    "start_time": "2023-12-05T13:03:15.486Z"
   },
   {
    "duration": 13,
    "start_time": "2023-12-05T13:03:15.493Z"
   },
   {
    "duration": 7478,
    "start_time": "2023-12-05T13:03:15.508Z"
   },
   {
    "duration": 10,
    "start_time": "2023-12-05T13:03:22.987Z"
   },
   {
    "duration": 30,
    "start_time": "2023-12-05T13:03:22.998Z"
   },
   {
    "duration": 39,
    "start_time": "2023-12-05T13:03:23.043Z"
   },
   {
    "duration": 146,
    "start_time": "2023-12-05T13:03:23.084Z"
   },
   {
    "duration": 13725,
    "start_time": "2023-12-05T13:03:23.231Z"
   },
   {
    "duration": 70824,
    "start_time": "2023-12-05T13:03:36.958Z"
   },
   {
    "duration": 72176,
    "start_time": "2023-12-05T13:04:47.786Z"
   },
   {
    "duration": 35785,
    "start_time": "2023-12-05T13:05:59.964Z"
   },
   {
    "duration": 126327,
    "start_time": "2023-12-05T13:06:35.751Z"
   },
   {
    "duration": 127506,
    "start_time": "2023-12-05T13:08:42.080Z"
   },
   {
    "duration": 11789,
    "start_time": "2023-12-05T13:10:49.587Z"
   },
   {
    "duration": 38116,
    "start_time": "2023-12-05T13:11:01.378Z"
   },
   {
    "duration": 1013755,
    "start_time": "2023-12-05T13:11:39.496Z"
   },
   {
    "duration": 203413,
    "start_time": "2023-12-05T13:28:33.253Z"
   },
   {
    "duration": 701898,
    "start_time": "2023-12-05T13:31:56.668Z"
   },
   {
    "duration": 15401,
    "start_time": "2023-12-05T13:43:38.568Z"
   },
   {
    "duration": 8481,
    "start_time": "2023-12-05T13:43:53.971Z"
   },
   {
    "duration": 145097,
    "start_time": "2023-12-05T13:44:02.454Z"
   },
   {
    "duration": 631755,
    "start_time": "2023-12-05T13:46:27.552Z"
   },
   {
    "duration": 2236,
    "start_time": "2023-12-05T14:10:36.603Z"
   },
   {
    "duration": 883,
    "start_time": "2023-12-05T14:10:38.842Z"
   },
   {
    "duration": 35,
    "start_time": "2023-12-05T14:10:39.726Z"
   },
   {
    "duration": 427,
    "start_time": "2023-12-05T14:10:39.763Z"
   },
   {
    "duration": 6,
    "start_time": "2023-12-05T14:10:40.193Z"
   },
   {
    "duration": 26,
    "start_time": "2023-12-05T14:10:40.201Z"
   },
   {
    "duration": 7447,
    "start_time": "2023-12-05T14:10:40.229Z"
   },
   {
    "duration": 11,
    "start_time": "2023-12-05T14:10:47.678Z"
   },
   {
    "duration": 92,
    "start_time": "2023-12-05T14:10:47.691Z"
   },
   {
    "duration": 41,
    "start_time": "2023-12-05T14:10:47.787Z"
   },
   {
    "duration": 157,
    "start_time": "2023-12-05T14:10:47.830Z"
   },
   {
    "duration": 13955,
    "start_time": "2023-12-05T14:10:47.990Z"
   },
   {
    "duration": 68815,
    "start_time": "2023-12-05T14:11:01.946Z"
   },
   {
    "duration": 70400,
    "start_time": "2023-12-05T14:12:10.762Z"
   },
   {
    "duration": 35085,
    "start_time": "2023-12-05T14:13:21.165Z"
   },
   {
    "duration": 125739,
    "start_time": "2023-12-05T14:13:56.252Z"
   },
   {
    "duration": 128908,
    "start_time": "2023-12-05T14:16:01.993Z"
   },
   {
    "duration": 12112,
    "start_time": "2023-12-05T14:18:10.902Z"
   },
   {
    "duration": 38493,
    "start_time": "2023-12-05T14:18:23.016Z"
   },
   {
    "duration": 1017228,
    "start_time": "2023-12-05T14:19:01.511Z"
   },
   {
    "duration": 205546,
    "start_time": "2023-12-05T14:35:58.740Z"
   },
   {
    "duration": 754678,
    "start_time": "2023-12-05T14:39:24.287Z"
   },
   {
    "duration": 15604,
    "start_time": "2023-12-05T14:51:58.967Z"
   },
   {
    "duration": 119,
    "start_time": "2023-12-05T14:52:14.573Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-05T14:52:14.693Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-05T14:52:14.694Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-05T14:52:14.695Z"
   },
   {
    "duration": 9159,
    "start_time": "2023-12-05T14:59:54.899Z"
   },
   {
    "duration": 144388,
    "start_time": "2023-12-05T15:00:09.841Z"
   },
   {
    "duration": 624973,
    "start_time": "2023-12-05T15:02:34.231Z"
   },
   {
    "duration": 2324,
    "start_time": "2023-12-08T09:19:17.089Z"
   },
   {
    "duration": 5,
    "start_time": "2023-12-08T09:19:27.009Z"
   },
   {
    "duration": 2237,
    "start_time": "2023-12-08T09:19:32.261Z"
   },
   {
    "duration": 31,
    "start_time": "2023-12-08T09:19:48.397Z"
   },
   {
    "duration": 387,
    "start_time": "2023-12-08T09:19:49.329Z"
   },
   {
    "duration": 6,
    "start_time": "2023-12-08T09:19:52.333Z"
   },
   {
    "duration": 13,
    "start_time": "2023-12-08T09:19:56.706Z"
   },
   {
    "duration": 4,
    "start_time": "2023-12-08T09:20:42.282Z"
   },
   {
    "duration": 486,
    "start_time": "2023-12-08T09:36:27.508Z"
   },
   {
    "duration": 2182,
    "start_time": "2023-12-08T09:46:50.823Z"
   },
   {
    "duration": 842,
    "start_time": "2023-12-08T09:48:33.743Z"
   },
   {
    "duration": 29,
    "start_time": "2023-12-08T09:48:34.587Z"
   },
   {
    "duration": 390,
    "start_time": "2023-12-08T09:48:34.781Z"
   },
   {
    "duration": 5,
    "start_time": "2023-12-08T09:48:37.204Z"
   },
   {
    "duration": 13,
    "start_time": "2023-12-08T09:48:39.747Z"
   },
   {
    "duration": 4,
    "start_time": "2023-12-08T09:48:40.415Z"
   },
   {
    "duration": 1415,
    "start_time": "2023-12-08T09:48:41.820Z"
   },
   {
    "duration": 11,
    "start_time": "2023-12-08T09:52:30.421Z"
   },
   {
    "duration": 11,
    "start_time": "2023-12-08T10:08:57.403Z"
   },
   {
    "duration": 11,
    "start_time": "2023-12-08T10:09:22.062Z"
   },
   {
    "duration": 2385,
    "start_time": "2023-12-08T10:09:39.013Z"
   },
   {
    "duration": 830,
    "start_time": "2023-12-08T10:09:41.399Z"
   },
   {
    "duration": 36,
    "start_time": "2023-12-08T10:09:42.230Z"
   },
   {
    "duration": 411,
    "start_time": "2023-12-08T10:09:42.268Z"
   },
   {
    "duration": 6,
    "start_time": "2023-12-08T10:09:44.030Z"
   },
   {
    "duration": 14,
    "start_time": "2023-12-08T10:09:46.260Z"
   },
   {
    "duration": 4,
    "start_time": "2023-12-08T10:09:47.293Z"
   },
   {
    "duration": 1422,
    "start_time": "2023-12-08T10:09:49.609Z"
   },
   {
    "duration": 13,
    "start_time": "2023-12-08T10:11:23.290Z"
   },
   {
    "duration": 2227,
    "start_time": "2023-12-08T10:12:49.106Z"
   },
   {
    "duration": 864,
    "start_time": "2023-12-08T10:12:51.334Z"
   },
   {
    "duration": 33,
    "start_time": "2023-12-08T10:12:53.373Z"
   },
   {
    "duration": 404,
    "start_time": "2023-12-08T10:12:53.959Z"
   },
   {
    "duration": 6,
    "start_time": "2023-12-08T10:12:56.387Z"
   },
   {
    "duration": 14,
    "start_time": "2023-12-08T10:12:57.855Z"
   },
   {
    "duration": 2,
    "start_time": "2023-12-08T10:12:58.699Z"
   },
   {
    "duration": 720,
    "start_time": "2023-12-08T10:12:59.627Z"
   },
   {
    "duration": 429,
    "start_time": "2023-12-08T10:13:52.024Z"
   },
   {
    "duration": 1331,
    "start_time": "2023-12-08T10:17:08.388Z"
   },
   {
    "duration": 347,
    "start_time": "2023-12-08T10:26:23.791Z"
   },
   {
    "duration": 8,
    "start_time": "2023-12-08T10:27:12.482Z"
   },
   {
    "duration": 48,
    "start_time": "2023-12-08T10:27:13.726Z"
   },
   {
    "duration": 2210,
    "start_time": "2023-12-08T10:27:47.694Z"
   },
   {
    "duration": 844,
    "start_time": "2023-12-08T10:27:51.032Z"
   },
   {
    "duration": 32,
    "start_time": "2023-12-08T10:27:52.927Z"
   },
   {
    "duration": 399,
    "start_time": "2023-12-08T10:27:53.683Z"
   },
   {
    "duration": 6,
    "start_time": "2023-12-08T10:27:54.979Z"
   },
   {
    "duration": 13,
    "start_time": "2023-12-08T10:27:56.807Z"
   },
   {
    "duration": 4,
    "start_time": "2023-12-08T10:27:57.587Z"
   },
   {
    "duration": 1411,
    "start_time": "2023-12-08T10:27:59.139Z"
   },
   {
    "duration": 134,
    "start_time": "2023-12-08T10:31:44.447Z"
   },
   {
    "duration": 1352052,
    "start_time": "2023-12-08T10:32:03.549Z"
   },
   {
    "duration": 35,
    "start_time": "2023-12-08T10:55:16.876Z"
   },
   {
    "duration": 96,
    "start_time": "2023-12-08T10:56:55.497Z"
   },
   {
    "duration": 90,
    "start_time": "2023-12-08T10:57:01.294Z"
   },
   {
    "duration": 88,
    "start_time": "2023-12-08T10:57:06.791Z"
   },
   {
    "duration": 67,
    "start_time": "2023-12-08T10:57:12.338Z"
   },
   {
    "duration": 66,
    "start_time": "2023-12-08T10:57:16.466Z"
   },
   {
    "duration": 68,
    "start_time": "2023-12-08T10:57:23.639Z"
   },
   {
    "duration": 68,
    "start_time": "2023-12-08T10:57:27.729Z"
   },
   {
    "duration": 66,
    "start_time": "2023-12-08T10:57:38.077Z"
   },
   {
    "duration": 78,
    "start_time": "2023-12-08T10:57:43.067Z"
   },
   {
    "duration": 75,
    "start_time": "2023-12-08T10:57:51.430Z"
   },
   {
    "duration": 76,
    "start_time": "2023-12-08T10:58:15.132Z"
   },
   {
    "duration": 12,
    "start_time": "2023-12-08T10:59:25.430Z"
   },
   {
    "duration": 12,
    "start_time": "2023-12-08T10:59:43.278Z"
   },
   {
    "duration": 28,
    "start_time": "2023-12-08T10:59:44.189Z"
   },
   {
    "duration": 41,
    "start_time": "2023-12-08T11:00:41.617Z"
   },
   {
    "duration": 17,
    "start_time": "2023-12-08T11:02:11.930Z"
   },
   {
    "duration": 16,
    "start_time": "2023-12-08T11:04:12.840Z"
   },
   {
    "duration": 31,
    "start_time": "2023-12-08T11:05:19.867Z"
   },
   {
    "duration": 31,
    "start_time": "2023-12-08T11:06:16.184Z"
   },
   {
    "duration": 49,
    "start_time": "2023-12-08T11:06:31.735Z"
   },
   {
    "duration": 36,
    "start_time": "2023-12-08T11:06:45.093Z"
   },
   {
    "duration": 130,
    "start_time": "2023-12-08T11:09:50.177Z"
   },
   {
    "duration": 32,
    "start_time": "2023-12-08T11:11:13.612Z"
   },
   {
    "duration": 132,
    "start_time": "2023-12-08T11:11:18.915Z"
   },
   {
    "duration": 31,
    "start_time": "2023-12-08T11:11:30.438Z"
   },
   {
    "duration": 125,
    "start_time": "2023-12-08T11:11:32.302Z"
   },
   {
    "duration": 10590,
    "start_time": "2023-12-08T11:11:39.804Z"
   },
   {
    "duration": 5318,
    "start_time": "2023-12-08T11:12:36.318Z"
   },
   {
    "duration": 16,
    "start_time": "2023-12-08T11:14:19.099Z"
   },
   {
    "duration": 15,
    "start_time": "2023-12-08T11:19:35.185Z"
   },
   {
    "duration": 16,
    "start_time": "2023-12-08T11:20:41.168Z"
   },
   {
    "duration": 14,
    "start_time": "2023-12-08T11:20:59.016Z"
   },
   {
    "duration": 14,
    "start_time": "2023-12-08T11:23:51.692Z"
   },
   {
    "duration": 15,
    "start_time": "2023-12-08T11:24:01.110Z"
   },
   {
    "duration": 2328,
    "start_time": "2023-12-08T11:43:47.375Z"
   },
   {
    "duration": 847,
    "start_time": "2023-12-08T11:43:49.705Z"
   },
   {
    "duration": 31,
    "start_time": "2023-12-08T11:43:50.554Z"
   },
   {
    "duration": 402,
    "start_time": "2023-12-08T11:43:50.587Z"
   },
   {
    "duration": 7,
    "start_time": "2023-12-08T11:43:50.991Z"
   },
   {
    "duration": 23,
    "start_time": "2023-12-08T11:43:50.999Z"
   },
   {
    "duration": 6,
    "start_time": "2023-12-08T11:43:51.024Z"
   },
   {
    "duration": 1412,
    "start_time": "2023-12-08T11:43:51.032Z"
   },
   {
    "duration": 8701,
    "start_time": "2023-12-08T11:43:52.446Z"
   },
   {
    "duration": 33,
    "start_time": "2023-12-08T11:44:01.149Z"
   },
   {
    "duration": 67,
    "start_time": "2023-12-08T11:44:01.184Z"
   },
   {
    "duration": 55,
    "start_time": "2023-12-08T11:44:01.253Z"
   },
   {
    "duration": 14,
    "start_time": "2023-12-08T11:44:01.310Z"
   },
   {
    "duration": 29,
    "start_time": "2023-12-08T11:44:01.327Z"
   },
   {
    "duration": 154,
    "start_time": "2023-12-08T11:44:01.357Z"
   },
   {
    "duration": 151,
    "start_time": "2023-12-08T11:44:01.512Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-08T11:44:01.665Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-08T11:44:01.666Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-08T11:44:01.667Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-08T11:44:01.668Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-08T11:44:01.669Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-08T11:44:01.670Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-08T11:44:01.671Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-08T11:44:01.672Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-08T11:44:01.673Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-08T11:44:01.675Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-08T11:44:01.676Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-08T11:44:01.677Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-08T11:44:01.680Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-08T11:44:01.681Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-08T11:44:01.682Z"
   },
   {
    "duration": 8,
    "start_time": "2023-12-08T11:45:21.244Z"
   },
   {
    "duration": 2244,
    "start_time": "2023-12-08T11:46:40.221Z"
   },
   {
    "duration": 852,
    "start_time": "2023-12-08T11:46:42.467Z"
   },
   {
    "duration": 29,
    "start_time": "2023-12-08T11:46:43.321Z"
   },
   {
    "duration": 407,
    "start_time": "2023-12-08T11:46:43.351Z"
   },
   {
    "duration": 6,
    "start_time": "2023-12-08T11:46:43.765Z"
   },
   {
    "duration": 13,
    "start_time": "2023-12-08T11:46:43.773Z"
   },
   {
    "duration": 6,
    "start_time": "2023-12-08T11:46:43.788Z"
   },
   {
    "duration": 1471,
    "start_time": "2023-12-08T11:46:43.796Z"
   },
   {
    "duration": 3,
    "start_time": "2023-12-08T11:46:45.269Z"
   },
   {
    "duration": 8528,
    "start_time": "2023-12-08T11:46:45.274Z"
   },
   {
    "duration": 11,
    "start_time": "2023-12-08T11:46:53.803Z"
   },
   {
    "duration": 16,
    "start_time": "2023-12-08T11:46:53.816Z"
   },
   {
    "duration": 26,
    "start_time": "2023-12-08T11:46:53.834Z"
   },
   {
    "duration": 24,
    "start_time": "2023-12-08T11:46:53.862Z"
   },
   {
    "duration": 40,
    "start_time": "2023-12-08T11:46:53.887Z"
   },
   {
    "duration": 23,
    "start_time": "2023-12-08T11:46:53.928Z"
   },
   {
    "duration": 137,
    "start_time": "2023-12-08T11:46:53.952Z"
   },
   {
    "duration": 52,
    "start_time": "2023-12-08T11:46:54.091Z"
   },
   {
    "duration": 162,
    "start_time": "2023-12-08T11:46:54.144Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-08T11:46:54.307Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-08T11:46:54.308Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-08T11:46:54.310Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-08T11:46:54.310Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-08T11:46:54.312Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-08T11:46:54.312Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-08T11:46:54.314Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-08T11:46:54.315Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-08T11:46:54.316Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-08T11:46:54.316Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-08T11:46:54.318Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-08T11:46:54.319Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-08T11:46:54.320Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-08T11:46:54.321Z"
   },
   {
    "duration": 21,
    "start_time": "2023-12-08T11:48:54.083Z"
   },
   {
    "duration": 2178,
    "start_time": "2023-12-08T11:57:10.254Z"
   },
   {
    "duration": 851,
    "start_time": "2023-12-08T11:57:12.434Z"
   },
   {
    "duration": 32,
    "start_time": "2023-12-08T11:57:13.287Z"
   },
   {
    "duration": 403,
    "start_time": "2023-12-08T11:57:13.321Z"
   },
   {
    "duration": 5,
    "start_time": "2023-12-08T11:57:13.725Z"
   },
   {
    "duration": 15,
    "start_time": "2023-12-08T11:57:13.732Z"
   },
   {
    "duration": 20,
    "start_time": "2023-12-08T11:57:13.748Z"
   },
   {
    "duration": 1533,
    "start_time": "2023-12-08T11:57:13.769Z"
   },
   {
    "duration": 3,
    "start_time": "2023-12-08T11:57:15.303Z"
   },
   {
    "duration": 8546,
    "start_time": "2023-12-08T11:57:15.308Z"
   },
   {
    "duration": 18,
    "start_time": "2023-12-08T11:57:23.855Z"
   },
   {
    "duration": 6,
    "start_time": "2023-12-08T11:57:23.875Z"
   },
   {
    "duration": 24,
    "start_time": "2023-12-08T11:57:23.882Z"
   },
   {
    "duration": 24,
    "start_time": "2023-12-08T11:57:23.907Z"
   },
   {
    "duration": 29,
    "start_time": "2023-12-08T11:57:23.932Z"
   },
   {
    "duration": 13,
    "start_time": "2023-12-08T11:57:23.962Z"
   },
   {
    "duration": 139,
    "start_time": "2023-12-08T11:57:23.976Z"
   },
   {
    "duration": 65,
    "start_time": "2023-12-08T11:57:24.117Z"
   },
   {
    "duration": 1493,
    "start_time": "2023-12-08T11:57:24.184Z"
   },
   {
    "duration": 49,
    "start_time": "2023-12-08T11:57:25.679Z"
   },
   {
    "duration": 70,
    "start_time": "2023-12-08T11:57:25.730Z"
   },
   {
    "duration": 42,
    "start_time": "2023-12-08T11:57:25.802Z"
   },
   {
    "duration": 229,
    "start_time": "2023-12-08T11:57:25.846Z"
   },
   {
    "duration": 221,
    "start_time": "2023-12-08T11:57:26.077Z"
   },
   {
    "duration": 110,
    "start_time": "2023-12-08T11:57:26.299Z"
   },
   {
    "duration": 812,
    "start_time": "2023-12-08T11:57:26.411Z"
   },
   {
    "duration": 8750,
    "start_time": "2023-12-08T11:57:27.225Z"
   },
   {
    "duration": 4458,
    "start_time": "2023-12-08T11:57:35.978Z"
   },
   {
    "duration": 8238,
    "start_time": "2023-12-08T11:57:40.438Z"
   },
   {
    "duration": 295,
    "start_time": "2023-12-08T11:57:48.678Z"
   },
   {
    "duration": 26,
    "start_time": "2023-12-08T11:57:48.975Z"
   },
   {
    "duration": 2747,
    "start_time": "2023-12-08T11:57:49.002Z"
   },
   {
    "duration": 7194,
    "start_time": "2023-12-08T11:57:51.750Z"
   },
   {
    "duration": 2290,
    "start_time": "2023-12-08T11:58:26.254Z"
   },
   {
    "duration": 832,
    "start_time": "2023-12-08T11:58:28.546Z"
   },
   {
    "duration": 31,
    "start_time": "2023-12-08T11:58:29.380Z"
   },
   {
    "duration": 415,
    "start_time": "2023-12-08T11:58:29.413Z"
   },
   {
    "duration": 6,
    "start_time": "2023-12-08T11:58:29.830Z"
   },
   {
    "duration": 28,
    "start_time": "2023-12-08T11:58:29.838Z"
   },
   {
    "duration": 3,
    "start_time": "2023-12-08T11:58:29.868Z"
   },
   {
    "duration": 1469,
    "start_time": "2023-12-08T11:58:29.873Z"
   },
   {
    "duration": 3,
    "start_time": "2023-12-08T11:58:31.345Z"
   },
   {
    "duration": 8773,
    "start_time": "2023-12-08T11:58:31.351Z"
   },
   {
    "duration": 11,
    "start_time": "2023-12-08T11:58:40.125Z"
   },
   {
    "duration": 8,
    "start_time": "2023-12-08T11:58:40.138Z"
   },
   {
    "duration": 20,
    "start_time": "2023-12-08T11:58:40.147Z"
   },
   {
    "duration": 12,
    "start_time": "2023-12-08T11:58:40.168Z"
   },
   {
    "duration": 9,
    "start_time": "2023-12-08T11:58:40.181Z"
   },
   {
    "duration": 17,
    "start_time": "2023-12-08T11:58:40.191Z"
   },
   {
    "duration": 146,
    "start_time": "2023-12-08T11:58:40.209Z"
   },
   {
    "duration": 56,
    "start_time": "2023-12-08T11:58:40.356Z"
   },
   {
    "duration": 614,
    "start_time": "2023-12-08T11:58:40.413Z"
   },
   {
    "duration": 56,
    "start_time": "2023-12-08T11:58:41.028Z"
   },
   {
    "duration": 44,
    "start_time": "2023-12-08T11:58:41.086Z"
   },
   {
    "duration": 56,
    "start_time": "2023-12-08T11:58:41.132Z"
   },
   {
    "duration": 189,
    "start_time": "2023-12-08T11:58:41.189Z"
   },
   {
    "duration": 202,
    "start_time": "2023-12-08T11:58:41.379Z"
   },
   {
    "duration": 94,
    "start_time": "2023-12-08T11:58:41.583Z"
   },
   {
    "duration": 727,
    "start_time": "2023-12-08T11:58:41.678Z"
   },
   {
    "duration": 9000,
    "start_time": "2023-12-08T11:58:42.407Z"
   },
   {
    "duration": 4562,
    "start_time": "2023-12-08T11:58:51.410Z"
   },
   {
    "duration": 7498,
    "start_time": "2023-12-08T11:58:55.973Z"
   },
   {
    "duration": 205,
    "start_time": "2023-12-08T11:59:03.473Z"
   },
   {
    "duration": 29,
    "start_time": "2023-12-08T11:59:03.765Z"
   },
   {
    "duration": 2806,
    "start_time": "2023-12-08T11:59:03.796Z"
   },
   {
    "duration": 7201,
    "start_time": "2023-12-08T11:59:06.603Z"
   },
   {
    "duration": 8881,
    "start_time": "2023-12-08T12:01:08.791Z"
   },
   {
    "duration": 140,
    "start_time": "2023-12-08T12:06:35.268Z"
   },
   {
    "duration": 13,
    "start_time": "2023-12-08T12:10:31.076Z"
   },
   {
    "duration": 12,
    "start_time": "2023-12-08T12:11:11.485Z"
   },
   {
    "duration": 4864,
    "start_time": "2023-12-08T12:11:18.585Z"
   },
   {
    "duration": 16,
    "start_time": "2023-12-08T12:12:26.974Z"
   },
   {
    "duration": 16,
    "start_time": "2023-12-08T12:12:37.246Z"
   },
   {
    "duration": 5493,
    "start_time": "2023-12-08T12:15:20.895Z"
   },
   {
    "duration": 23,
    "start_time": "2023-12-08T12:16:10.910Z"
   },
   {
    "duration": 2405,
    "start_time": "2023-12-08T12:18:07.674Z"
   },
   {
    "duration": 853,
    "start_time": "2023-12-08T12:18:10.081Z"
   },
   {
    "duration": 37,
    "start_time": "2023-12-08T12:18:10.935Z"
   },
   {
    "duration": 402,
    "start_time": "2023-12-08T12:18:10.974Z"
   },
   {
    "duration": 6,
    "start_time": "2023-12-08T12:18:11.378Z"
   },
   {
    "duration": 24,
    "start_time": "2023-12-08T12:18:11.385Z"
   },
   {
    "duration": 4,
    "start_time": "2023-12-08T12:18:11.410Z"
   },
   {
    "duration": 1400,
    "start_time": "2023-12-08T12:18:11.415Z"
   },
   {
    "duration": 2,
    "start_time": "2023-12-08T12:18:12.817Z"
   },
   {
    "duration": 8627,
    "start_time": "2023-12-08T12:18:12.821Z"
   },
   {
    "duration": 17,
    "start_time": "2023-12-08T12:18:21.450Z"
   },
   {
    "duration": 47,
    "start_time": "2023-12-08T12:18:21.469Z"
   },
   {
    "duration": 47,
    "start_time": "2023-12-08T12:18:21.518Z"
   },
   {
    "duration": 47,
    "start_time": "2023-12-08T12:18:21.567Z"
   },
   {
    "duration": 56,
    "start_time": "2023-12-08T12:18:21.616Z"
   },
   {
    "duration": 42,
    "start_time": "2023-12-08T12:18:21.674Z"
   },
   {
    "duration": 173,
    "start_time": "2023-12-08T12:18:21.718Z"
   },
   {
    "duration": 51,
    "start_time": "2023-12-08T12:18:21.893Z"
   },
   {
    "duration": 161,
    "start_time": "2023-12-08T12:18:21.946Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-08T12:18:22.108Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-08T12:18:22.110Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-08T12:18:22.111Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-08T12:18:22.111Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-08T12:18:22.112Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-08T12:18:22.113Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-08T12:18:22.114Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-08T12:18:22.115Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-08T12:18:22.116Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-08T12:18:22.117Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-08T12:18:22.118Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-08T12:18:22.119Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-08T12:18:22.120Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-08T12:18:22.120Z"
   },
   {
    "duration": 2190,
    "start_time": "2023-12-08T12:19:15.119Z"
   },
   {
    "duration": 833,
    "start_time": "2023-12-08T12:19:17.310Z"
   },
   {
    "duration": 31,
    "start_time": "2023-12-08T12:19:18.145Z"
   },
   {
    "duration": 423,
    "start_time": "2023-12-08T12:19:18.178Z"
   },
   {
    "duration": 6,
    "start_time": "2023-12-08T12:19:18.602Z"
   },
   {
    "duration": 17,
    "start_time": "2023-12-08T12:19:18.610Z"
   },
   {
    "duration": 8,
    "start_time": "2023-12-08T12:19:18.628Z"
   },
   {
    "duration": 1491,
    "start_time": "2023-12-08T12:19:18.638Z"
   },
   {
    "duration": 3,
    "start_time": "2023-12-08T12:19:20.131Z"
   },
   {
    "duration": 8461,
    "start_time": "2023-12-08T12:19:20.137Z"
   },
   {
    "duration": 11,
    "start_time": "2023-12-08T12:19:28.600Z"
   },
   {
    "duration": 50,
    "start_time": "2023-12-08T12:19:28.612Z"
   },
   {
    "duration": 14,
    "start_time": "2023-12-08T12:19:28.664Z"
   },
   {
    "duration": 18,
    "start_time": "2023-12-08T12:19:28.679Z"
   },
   {
    "duration": 8,
    "start_time": "2023-12-08T12:19:28.698Z"
   },
   {
    "duration": 30,
    "start_time": "2023-12-08T12:19:28.707Z"
   },
   {
    "duration": 120,
    "start_time": "2023-12-08T12:19:28.739Z"
   },
   {
    "duration": 63,
    "start_time": "2023-12-08T12:19:28.860Z"
   },
   {
    "duration": 42,
    "start_time": "2023-12-08T12:19:28.924Z"
   },
   {
    "duration": 43,
    "start_time": "2023-12-08T12:19:28.968Z"
   },
   {
    "duration": 57,
    "start_time": "2023-12-08T12:19:29.013Z"
   },
   {
    "duration": 35,
    "start_time": "2023-12-08T12:19:29.071Z"
   },
   {
    "duration": 186,
    "start_time": "2023-12-08T12:19:29.107Z"
   },
   {
    "duration": 201,
    "start_time": "2023-12-08T12:19:29.294Z"
   },
   {
    "duration": 94,
    "start_time": "2023-12-08T12:19:29.497Z"
   },
   {
    "duration": 716,
    "start_time": "2023-12-08T12:19:29.592Z"
   },
   {
    "duration": 9087,
    "start_time": "2023-12-08T12:19:30.310Z"
   },
   {
    "duration": 4855,
    "start_time": "2023-12-08T12:19:39.400Z"
   },
   {
    "duration": 7524,
    "start_time": "2023-12-08T12:19:44.257Z"
   },
   {
    "duration": 306,
    "start_time": "2023-12-08T12:19:51.782Z"
   },
   {
    "duration": 26,
    "start_time": "2023-12-08T12:19:52.166Z"
   },
   {
    "duration": 2778,
    "start_time": "2023-12-08T12:19:52.194Z"
   },
   {
    "duration": 7055,
    "start_time": "2023-12-08T12:19:54.974Z"
   },
   {
    "duration": 37,
    "start_time": "2023-12-08T12:21:07.624Z"
   },
   {
    "duration": 31,
    "start_time": "2023-12-08T12:22:43.242Z"
   },
   {
    "duration": 34,
    "start_time": "2023-12-08T12:23:16.521Z"
   },
   {
    "duration": 5418,
    "start_time": "2023-12-08T12:23:34.979Z"
   },
   {
    "duration": 2588,
    "start_time": "2023-12-08T12:24:38.418Z"
   },
   {
    "duration": 72,
    "start_time": "2023-12-08T12:30:55.487Z"
   },
   {
    "duration": 3200,
    "start_time": "2023-12-08T12:32:42.447Z"
   },
   {
    "duration": 73,
    "start_time": "2023-12-08T12:33:02.911Z"
   },
   {
    "duration": 2115,
    "start_time": "2023-12-08T12:33:50.791Z"
   },
   {
    "duration": 855,
    "start_time": "2023-12-08T12:33:52.908Z"
   },
   {
    "duration": 28,
    "start_time": "2023-12-08T12:33:53.766Z"
   },
   {
    "duration": 402,
    "start_time": "2023-12-08T12:33:53.795Z"
   },
   {
    "duration": 6,
    "start_time": "2023-12-08T12:33:54.199Z"
   },
   {
    "duration": 18,
    "start_time": "2023-12-08T12:33:57.631Z"
   },
   {
    "duration": 3,
    "start_time": "2023-12-08T12:33:58.239Z"
   },
   {
    "duration": 1401,
    "start_time": "2023-12-08T12:33:58.855Z"
   },
   {
    "duration": 3,
    "start_time": "2023-12-08T12:34:01.453Z"
   },
   {
    "duration": 41911,
    "start_time": "2023-12-08T12:34:03.435Z"
   },
   {
    "duration": 11,
    "start_time": "2023-12-08T12:35:01.405Z"
   },
   {
    "duration": 8,
    "start_time": "2023-12-08T12:35:02.409Z"
   },
   {
    "duration": 3,
    "start_time": "2023-12-08T12:35:05.684Z"
   },
   {
    "duration": 10,
    "start_time": "2023-12-08T12:35:06.479Z"
   },
   {
    "duration": 9,
    "start_time": "2023-12-08T12:35:06.973Z"
   },
   {
    "duration": 14,
    "start_time": "2023-12-08T12:35:08.343Z"
   },
   {
    "duration": 124,
    "start_time": "2023-12-08T12:35:10.099Z"
   },
   {
    "duration": 233,
    "start_time": "2023-12-08T12:35:10.699Z"
   },
   {
    "duration": 34033,
    "start_time": "2023-12-08T12:35:18.538Z"
   },
   {
    "duration": 1175,
    "start_time": "2023-12-08T12:37:27.792Z"
   },
   {
    "duration": 162,
    "start_time": "2023-12-08T12:38:22.614Z"
   },
   {
    "duration": 741,
    "start_time": "2023-12-08T12:39:04.347Z"
   },
   {
    "duration": 785,
    "start_time": "2023-12-08T12:39:10.300Z"
   },
   {
    "duration": 136,
    "start_time": "2023-12-08T12:42:39.141Z"
   },
   {
    "duration": 1190,
    "start_time": "2023-12-08T12:45:20.006Z"
   },
   {
    "duration": 134,
    "start_time": "2023-12-08T12:48:50.143Z"
   },
   {
    "duration": 89,
    "start_time": "2023-12-08T12:49:11.527Z"
   },
   {
    "duration": 1189,
    "start_time": "2023-12-08T12:50:46.176Z"
   },
   {
    "duration": 1195,
    "start_time": "2023-12-08T12:52:06.324Z"
   },
   {
    "duration": 28174,
    "start_time": "2023-12-08T12:53:39.853Z"
   },
   {
    "duration": 7301,
    "start_time": "2023-12-08T12:56:45.106Z"
   },
   {
    "duration": 19,
    "start_time": "2023-12-08T13:00:44.083Z"
   },
   {
    "duration": 23241,
    "start_time": "2023-12-08T13:05:39.935Z"
   },
   {
    "duration": 23012,
    "start_time": "2023-12-08T13:08:45.455Z"
   },
   {
    "duration": 2184,
    "start_time": "2023-12-08T13:11:03.438Z"
   },
   {
    "duration": 890,
    "start_time": "2023-12-08T13:11:05.624Z"
   },
   {
    "duration": 27,
    "start_time": "2023-12-08T13:11:06.515Z"
   },
   {
    "duration": 402,
    "start_time": "2023-12-08T13:11:06.543Z"
   },
   {
    "duration": 6,
    "start_time": "2023-12-08T13:11:06.946Z"
   },
   {
    "duration": 13,
    "start_time": "2023-12-08T13:11:07.414Z"
   },
   {
    "duration": 4,
    "start_time": "2023-12-08T13:11:08.534Z"
   },
   {
    "duration": 1452,
    "start_time": "2023-12-08T13:11:10.164Z"
   },
   {
    "duration": 3,
    "start_time": "2023-12-08T13:11:13.870Z"
   },
   {
    "duration": 41363,
    "start_time": "2023-12-08T13:11:15.429Z"
   },
   {
    "duration": 11,
    "start_time": "2023-12-08T13:12:08.454Z"
   },
   {
    "duration": 9,
    "start_time": "2023-12-08T13:12:11.857Z"
   },
   {
    "duration": 4,
    "start_time": "2023-12-08T13:12:17.714Z"
   },
   {
    "duration": 10,
    "start_time": "2023-12-08T13:12:18.506Z"
   },
   {
    "duration": 9,
    "start_time": "2023-12-08T13:12:19.523Z"
   },
   {
    "duration": 15,
    "start_time": "2023-12-08T13:12:23.313Z"
   },
   {
    "duration": 136,
    "start_time": "2023-12-08T13:12:28.638Z"
   },
   {
    "duration": 240,
    "start_time": "2023-12-08T13:12:32.286Z"
   },
   {
    "duration": 29302,
    "start_time": "2023-12-08T13:12:42.562Z"
   },
   {
    "duration": 19379,
    "start_time": "2023-12-08T13:13:32.987Z"
   },
   {
    "duration": 258,
    "start_time": "2023-12-08T13:14:49.915Z"
   },
   {
    "duration": 751,
    "start_time": "2023-12-08T13:16:14.287Z"
   },
   {
    "duration": 799,
    "start_time": "2023-12-08T13:16:24.285Z"
   },
   {
    "duration": 138,
    "start_time": "2023-12-08T13:16:37.835Z"
   },
   {
    "duration": 1205,
    "start_time": "2023-12-08T13:16:50.517Z"
   },
   {
    "duration": 28967,
    "start_time": "2023-12-08T13:17:31.616Z"
   },
   {
    "duration": 6778,
    "start_time": "2023-12-08T13:18:20.051Z"
   },
   {
    "duration": 21530,
    "start_time": "2023-12-08T13:19:19.040Z"
   },
   {
    "duration": 23372,
    "start_time": "2023-12-08T13:20:03.596Z"
   },
   {
    "duration": 2848,
    "start_time": "2023-12-08T13:47:12.501Z"
   },
   {
    "duration": 884,
    "start_time": "2023-12-08T13:47:15.351Z"
   },
   {
    "duration": 37,
    "start_time": "2023-12-08T13:47:16.236Z"
   },
   {
    "duration": 413,
    "start_time": "2023-12-08T13:47:16.275Z"
   },
   {
    "duration": 7,
    "start_time": "2023-12-08T13:47:16.689Z"
   },
   {
    "duration": 35,
    "start_time": "2023-12-08T13:47:16.697Z"
   },
   {
    "duration": 25,
    "start_time": "2023-12-08T13:47:16.734Z"
   },
   {
    "duration": 1444,
    "start_time": "2023-12-08T13:47:16.761Z"
   },
   {
    "duration": 2,
    "start_time": "2023-12-08T13:47:18.206Z"
   },
   {
    "duration": 1329785,
    "start_time": "2023-12-08T13:47:18.211Z"
   },
   {
    "duration": 13,
    "start_time": "2023-12-08T14:09:27.997Z"
   },
   {
    "duration": 37,
    "start_time": "2023-12-08T14:09:28.011Z"
   },
   {
    "duration": 22,
    "start_time": "2023-12-08T14:09:28.050Z"
   },
   {
    "duration": 48,
    "start_time": "2023-12-08T14:09:28.073Z"
   },
   {
    "duration": 24,
    "start_time": "2023-12-08T14:09:28.123Z"
   },
   {
    "duration": 61,
    "start_time": "2023-12-08T14:09:28.149Z"
   },
   {
    "duration": 129,
    "start_time": "2023-12-08T14:09:28.212Z"
   },
   {
    "duration": 7313,
    "start_time": "2023-12-08T14:09:28.343Z"
   },
   {
    "duration": 49220,
    "start_time": "2023-12-08T14:09:35.658Z"
   },
   {
    "duration": 75395,
    "start_time": "2023-12-08T14:10:24.879Z"
   },
   {
    "duration": 14293,
    "start_time": "2023-12-08T14:11:40.276Z"
   },
   {
    "duration": 76333,
    "start_time": "2023-12-08T14:11:54.571Z"
   },
   {
    "duration": 80237,
    "start_time": "2023-12-08T14:13:10.905Z"
   },
   {
    "duration": 12257,
    "start_time": "2023-12-08T14:14:31.143Z"
   },
   {
    "duration": 26555,
    "start_time": "2023-12-08T14:14:43.402Z"
   },
   {
    "duration": 462497,
    "start_time": "2023-12-08T14:15:09.959Z"
   },
   {
    "duration": 123137,
    "start_time": "2023-12-08T14:22:52.458Z"
   },
   {
    "duration": 411915,
    "start_time": "2023-12-08T14:24:55.599Z"
   },
   {
    "duration": 319404,
    "start_time": "2023-12-08T14:31:47.566Z"
   },
   {
    "duration": 15101,
    "start_time": "2023-12-08T14:37:06.971Z"
   },
   {
    "duration": 546,
    "start_time": "2023-12-08T14:39:15.244Z"
   },
   {
    "duration": 312,
    "start_time": "2023-12-08T14:40:07.935Z"
   },
   {
    "duration": 27,
    "start_time": "2023-12-08T14:40:34.411Z"
   },
   {
    "duration": 136,
    "start_time": "2023-12-08T14:41:06.700Z"
   },
   {
    "duration": 17,
    "start_time": "2023-12-08T14:55:27.629Z"
   },
   {
    "duration": 27496,
    "start_time": "2023-12-08T14:55:40.182Z"
   },
   {
    "duration": 10,
    "start_time": "2023-12-08T14:56:24.701Z"
   },
   {
    "duration": 9,
    "start_time": "2023-12-08T14:56:29.909Z"
   },
   {
    "duration": 10,
    "start_time": "2023-12-08T14:56:51.456Z"
   },
   {
    "duration": 10,
    "start_time": "2023-12-08T14:57:10.030Z"
   },
   {
    "duration": 9,
    "start_time": "2023-12-08T14:57:24.452Z"
   },
   {
    "duration": 9,
    "start_time": "2023-12-08T14:57:30.372Z"
   },
   {
    "duration": 10,
    "start_time": "2023-12-08T14:58:00.068Z"
   },
   {
    "duration": 11,
    "start_time": "2023-12-08T14:58:27.745Z"
   },
   {
    "duration": 26936,
    "start_time": "2023-12-08T14:58:39.061Z"
   },
   {
    "duration": 72,
    "start_time": "2023-12-08T15:00:56.291Z"
   },
   {
    "duration": 71,
    "start_time": "2023-12-08T15:02:58.262Z"
   },
   {
    "duration": 12,
    "start_time": "2023-12-08T15:03:03.823Z"
   },
   {
    "duration": 98765,
    "start_time": "2023-12-08T15:03:26.906Z"
   },
   {
    "duration": 13,
    "start_time": "2023-12-08T15:05:29.418Z"
   },
   {
    "duration": 153928,
    "start_time": "2023-12-08T15:08:03.648Z"
   },
   {
    "duration": 1523,
    "start_time": "2023-12-08T15:11:57.896Z"
   },
   {
    "duration": 121528,
    "start_time": "2023-12-08T15:16:18.145Z"
   },
   {
    "duration": 69,
    "start_time": "2023-12-08T15:18:19.675Z"
   },
   {
    "duration": 2142,
    "start_time": "2023-12-08T15:21:51.170Z"
   },
   {
    "duration": 867,
    "start_time": "2023-12-08T15:21:53.314Z"
   },
   {
    "duration": 28,
    "start_time": "2023-12-08T15:21:54.182Z"
   },
   {
    "duration": 396,
    "start_time": "2023-12-08T15:21:54.212Z"
   },
   {
    "duration": 7,
    "start_time": "2023-12-08T15:21:54.610Z"
   },
   {
    "duration": 22,
    "start_time": "2023-12-08T15:21:54.618Z"
   },
   {
    "duration": 28,
    "start_time": "2023-12-08T15:21:54.641Z"
   },
   {
    "duration": 1454,
    "start_time": "2023-12-08T15:21:54.671Z"
   },
   {
    "duration": 2,
    "start_time": "2023-12-08T15:21:56.127Z"
   },
   {
    "duration": 1331337,
    "start_time": "2023-12-08T15:21:56.131Z"
   },
   {
    "duration": 12,
    "start_time": "2023-12-08T15:44:07.470Z"
   },
   {
    "duration": 54,
    "start_time": "2023-12-08T15:44:07.483Z"
   },
   {
    "duration": 14,
    "start_time": "2023-12-08T15:44:07.538Z"
   },
   {
    "duration": 56,
    "start_time": "2023-12-08T15:44:07.555Z"
   },
   {
    "duration": 26,
    "start_time": "2023-12-08T15:44:07.612Z"
   },
   {
    "duration": 75,
    "start_time": "2023-12-08T15:44:07.640Z"
   },
   {
    "duration": 162,
    "start_time": "2023-12-08T15:44:07.716Z"
   },
   {
    "duration": 7342,
    "start_time": "2023-12-08T15:44:07.879Z"
   },
   {
    "duration": 162756,
    "start_time": "2023-12-08T15:44:15.222Z"
   },
   {
    "duration": 80895,
    "start_time": "2023-12-08T15:46:57.979Z"
   },
   {
    "duration": 13991,
    "start_time": "2023-12-08T15:48:18.876Z"
   },
   {
    "duration": 76268,
    "start_time": "2023-12-08T15:48:32.872Z"
   },
   {
    "duration": 78766,
    "start_time": "2023-12-08T15:49:49.141Z"
   },
   {
    "duration": 11868,
    "start_time": "2023-12-08T15:51:07.908Z"
   },
   {
    "duration": 25955,
    "start_time": "2023-12-08T15:51:19.778Z"
   },
   {
    "duration": 464020,
    "start_time": "2023-12-08T15:51:45.734Z"
   },
   {
    "duration": 121700,
    "start_time": "2023-12-08T15:59:29.756Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-08T16:01:31.458Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-08T16:01:31.459Z"
   },
   {
    "duration": 0,
    "start_time": "2023-12-08T16:01:31.460Z"
   },
   {
    "duration": 119177,
    "start_time": "2023-12-08T16:07:10.270Z"
   },
   {
    "duration": 398955,
    "start_time": "2023-12-08T16:09:15.838Z"
   },
   {
    "duration": 2,
    "start_time": "2023-12-08T16:27:09.473Z"
   },
   {
    "duration": 26210,
    "start_time": "2023-12-08T16:27:09.477Z"
   },
   {
    "duration": 2204,
    "start_time": "2023-12-08T16:36:28.695Z"
   },
   {
    "duration": 864,
    "start_time": "2023-12-08T16:36:30.901Z"
   },
   {
    "duration": 27,
    "start_time": "2023-12-08T16:36:31.767Z"
   },
   {
    "duration": 408,
    "start_time": "2023-12-08T16:36:31.796Z"
   },
   {
    "duration": 5,
    "start_time": "2023-12-08T16:36:32.206Z"
   },
   {
    "duration": 16,
    "start_time": "2023-12-08T16:36:32.212Z"
   },
   {
    "duration": 4,
    "start_time": "2023-12-08T16:36:32.229Z"
   },
   {
    "duration": 1495,
    "start_time": "2023-12-08T16:36:32.234Z"
   },
   {
    "duration": 1413303,
    "start_time": "2023-12-08T16:36:33.730Z"
   },
   {
    "duration": 11,
    "start_time": "2023-12-08T17:00:07.036Z"
   },
   {
    "duration": 53,
    "start_time": "2023-12-08T17:00:07.048Z"
   },
   {
    "duration": 9,
    "start_time": "2023-12-08T17:00:07.102Z"
   },
   {
    "duration": 55,
    "start_time": "2023-12-08T17:00:07.113Z"
   },
   {
    "duration": 21,
    "start_time": "2023-12-08T17:00:07.170Z"
   },
   {
    "duration": 47,
    "start_time": "2023-12-08T17:00:07.193Z"
   },
   {
    "duration": 134,
    "start_time": "2023-12-08T17:00:07.242Z"
   },
   {
    "duration": 7949,
    "start_time": "2023-12-08T17:00:07.378Z"
   },
   {
    "duration": 176955,
    "start_time": "2023-12-08T17:00:15.329Z"
   },
   {
    "duration": 306595,
    "start_time": "2023-12-08T17:03:12.285Z"
   },
   {
    "duration": 16488,
    "start_time": "2023-12-08T17:08:18.882Z"
   },
   {
    "duration": 82343,
    "start_time": "2023-12-08T17:08:35.372Z"
   },
   {
    "duration": 83732,
    "start_time": "2023-12-08T17:09:57.717Z"
   },
   {
    "duration": 12802,
    "start_time": "2023-12-08T17:11:21.451Z"
   },
   {
    "duration": 28016,
    "start_time": "2023-12-08T17:11:34.254Z"
   },
   {
    "duration": 489449,
    "start_time": "2023-12-08T17:12:02.272Z"
   },
   {
    "duration": 128544,
    "start_time": "2023-12-08T17:20:11.723Z"
   },
   {
    "duration": 1272909,
    "start_time": "2023-12-08T17:22:20.275Z"
   },
   {
    "duration": 2230,
    "start_time": "2023-12-08T17:54:47.584Z"
   },
   {
    "duration": 879,
    "start_time": "2023-12-08T17:54:49.816Z"
   },
   {
    "duration": 31,
    "start_time": "2023-12-08T17:54:50.697Z"
   },
   {
    "duration": 437,
    "start_time": "2023-12-08T17:54:50.729Z"
   },
   {
    "duration": 7,
    "start_time": "2023-12-08T17:54:51.174Z"
   },
   {
    "duration": 20,
    "start_time": "2023-12-08T17:54:51.182Z"
   },
   {
    "duration": 9,
    "start_time": "2023-12-08T17:54:51.204Z"
   },
   {
    "duration": 1586,
    "start_time": "2023-12-08T17:54:51.215Z"
   },
   {
    "duration": 1414419,
    "start_time": "2023-12-08T17:54:52.802Z"
   },
   {
    "duration": 11,
    "start_time": "2023-12-08T18:18:27.224Z"
   },
   {
    "duration": 49,
    "start_time": "2023-12-08T18:18:27.236Z"
   },
   {
    "duration": 9,
    "start_time": "2023-12-08T18:18:27.287Z"
   },
   {
    "duration": 42,
    "start_time": "2023-12-08T18:18:27.297Z"
   },
   {
    "duration": 17,
    "start_time": "2023-12-08T18:18:27.341Z"
   },
   {
    "duration": 49,
    "start_time": "2023-12-08T18:18:27.359Z"
   },
   {
    "duration": 152,
    "start_time": "2023-12-08T18:18:27.410Z"
   },
   {
    "duration": 7704,
    "start_time": "2023-12-08T18:18:27.565Z"
   },
   {
    "duration": 167597,
    "start_time": "2023-12-08T18:18:35.275Z"
   },
   {
    "duration": 284412,
    "start_time": "2023-12-08T18:21:22.874Z"
   },
   {
    "duration": 16378,
    "start_time": "2023-12-08T18:26:07.288Z"
   },
   {
    "duration": 81524,
    "start_time": "2023-12-08T18:26:23.668Z"
   },
   {
    "duration": 82887,
    "start_time": "2023-12-08T18:27:45.194Z"
   },
   {
    "duration": 13051,
    "start_time": "2023-12-08T18:29:08.083Z"
   },
   {
    "duration": 27600,
    "start_time": "2023-12-08T18:29:21.135Z"
   },
   {
    "duration": 2,
    "start_time": "2023-12-08T18:29:48.736Z"
   },
   {
    "duration": 4,
    "start_time": "2023-12-08T18:29:48.740Z"
   },
   {
    "duration": 4,
    "start_time": "2023-12-08T18:29:48.745Z"
   },
   {
    "duration": 17,
    "start_time": "2023-12-08T18:29:48.752Z"
   },
   {
    "duration": 18410,
    "start_time": "2023-12-08T18:29:48.771Z"
   },
   {
    "duration": 2278,
    "start_time": "2023-12-10T11:39:53.166Z"
   },
   {
    "duration": 2082,
    "start_time": "2023-12-10T11:39:55.446Z"
   },
   {
    "duration": 18,
    "start_time": "2023-12-10T11:39:57.529Z"
   },
   {
    "duration": 391,
    "start_time": "2023-12-10T11:39:57.549Z"
   },
   {
    "duration": 2192,
    "start_time": "2023-12-10T11:40:34.649Z"
   },
   {
    "duration": 806,
    "start_time": "2023-12-10T11:40:36.843Z"
   },
   {
    "duration": 27,
    "start_time": "2023-12-10T11:40:46.133Z"
   },
   {
    "duration": 369,
    "start_time": "2023-12-10T11:40:49.226Z"
   },
   {
    "duration": 7,
    "start_time": "2023-12-10T11:40:53.419Z"
   },
   {
    "duration": 12,
    "start_time": "2023-12-10T11:40:55.069Z"
   },
   {
    "duration": 3,
    "start_time": "2023-12-10T11:40:56.002Z"
   },
   {
    "duration": 1719,
    "start_time": "2023-12-10T11:41:00.096Z"
   },
   {
    "duration": 66,
    "start_time": "2023-12-10T11:41:41.101Z"
   },
   {
    "duration": 76,
    "start_time": "2023-12-10T11:49:47.666Z"
   },
   {
    "duration": 137,
    "start_time": "2023-12-10T11:50:06.334Z"
   },
   {
    "duration": 2043,
    "start_time": "2023-12-10T11:51:52.499Z"
   },
   {
    "duration": 782,
    "start_time": "2023-12-10T11:51:54.543Z"
   },
   {
    "duration": 26,
    "start_time": "2023-12-10T11:51:56.178Z"
   },
   {
    "duration": 385,
    "start_time": "2023-12-10T11:51:56.955Z"
   },
   {
    "duration": 6,
    "start_time": "2023-12-10T11:51:59.490Z"
   },
   {
    "duration": 12,
    "start_time": "2023-12-10T11:52:01.471Z"
   },
   {
    "duration": 4,
    "start_time": "2023-12-10T11:52:02.606Z"
   },
   {
    "duration": 1438,
    "start_time": "2023-12-10T11:52:03.418Z"
   },
   {
    "duration": 2,
    "start_time": "2023-12-10T11:52:06.727Z"
   },
   {
    "duration": 79116,
    "start_time": "2023-12-10T11:52:08.963Z"
   },
   {
    "duration": 10,
    "start_time": "2023-12-10T11:54:06.699Z"
   },
   {
    "duration": 9,
    "start_time": "2023-12-10T11:54:10.423Z"
   },
   {
    "duration": 4,
    "start_time": "2023-12-10T11:54:14.931Z"
   },
   {
    "duration": 11,
    "start_time": "2023-12-10T11:54:16.695Z"
   },
   {
    "duration": 2,
    "start_time": "2023-12-10T11:54:23.503Z"
   },
   {
    "duration": 3,
    "start_time": "2023-12-10T11:54:25.663Z"
   },
   {
    "duration": 139,
    "start_time": "2023-12-10T11:54:30.854Z"
   },
   {
    "duration": 2,
    "start_time": "2023-12-10T11:54:44.207Z"
   },
   {
    "duration": 13,
    "start_time": "2023-12-10T11:54:45.228Z"
   },
   {
    "duration": 13,
    "start_time": "2023-12-10T11:55:40.563Z"
   },
   {
    "duration": 375,
    "start_time": "2023-12-10T11:56:10.643Z"
   },
   {
    "duration": 123189,
    "start_time": "2023-12-10T11:57:31.487Z"
   },
   {
    "duration": 12,
    "start_time": "2023-12-10T12:00:14.780Z"
   },
   {
    "duration": 215711,
    "start_time": "2023-12-10T12:00:47.859Z"
   },
   {
    "duration": 2,
    "start_time": "2023-12-10T12:04:52.239Z"
   },
   {
    "duration": 1564,
    "start_time": "2023-12-10T12:05:30.967Z"
   },
   {
    "duration": 1536,
    "start_time": "2023-12-10T12:05:35.455Z"
   },
   {
    "duration": 1585,
    "start_time": "2023-12-10T12:08:01.034Z"
   },
   {
    "duration": 1558,
    "start_time": "2023-12-10T12:08:23.258Z"
   },
   {
    "duration": 3244,
    "start_time": "2023-12-10T12:10:59.593Z"
   },
   {
    "duration": 3222,
    "start_time": "2023-12-10T12:11:15.345Z"
   },
   {
    "duration": 2098,
    "start_time": "2023-12-10T12:17:08.968Z"
   },
   {
    "duration": 794,
    "start_time": "2023-12-10T12:17:11.068Z"
   },
   {
    "duration": 23,
    "start_time": "2023-12-10T12:17:11.863Z"
   },
   {
    "duration": 403,
    "start_time": "2023-12-10T12:17:11.887Z"
   },
   {
    "duration": 5,
    "start_time": "2023-12-10T12:17:12.293Z"
   },
   {
    "duration": 32,
    "start_time": "2023-12-10T12:17:12.299Z"
   },
   {
    "duration": 15,
    "start_time": "2023-12-10T12:17:12.332Z"
   },
   {
    "duration": 1403,
    "start_time": "2023-12-10T12:17:12.348Z"
   },
   {
    "duration": 2,
    "start_time": "2023-12-10T12:17:13.752Z"
   },
   {
    "duration": 1253989,
    "start_time": "2023-12-10T12:17:13.755Z"
   },
   {
    "duration": 24,
    "start_time": "2023-12-10T12:38:07.745Z"
   },
   {
    "duration": 23,
    "start_time": "2023-12-10T12:38:07.771Z"
   },
   {
    "duration": 7,
    "start_time": "2023-12-10T12:38:07.796Z"
   },
   {
    "duration": 59,
    "start_time": "2023-12-10T12:38:07.805Z"
   },
   {
    "duration": 2,
    "start_time": "2023-12-10T12:38:07.865Z"
   },
   {
    "duration": 85,
    "start_time": "2023-12-10T12:38:07.868Z"
   },
   {
    "duration": 64,
    "start_time": "2023-12-10T12:38:07.955Z"
   },
   {
    "duration": 5713,
    "start_time": "2023-12-10T12:38:08.020Z"
   },
   {
    "duration": 217668,
    "start_time": "2023-12-10T12:38:13.735Z"
   },
   {
    "duration": 360789,
    "start_time": "2023-12-10T12:41:51.405Z"
   },
   {
    "duration": 3,
    "start_time": "2023-12-10T12:47:52.195Z"
   },
   {
    "duration": 93365,
    "start_time": "2023-12-10T12:47:52.199Z"
   },
   {
    "duration": 96032,
    "start_time": "2023-12-10T12:49:25.566Z"
   },
   {
    "duration": 2,
    "start_time": "2023-12-10T12:51:01.600Z"
   },
   {
    "duration": 192161,
    "start_time": "2023-12-10T12:51:01.604Z"
   },
   {
    "duration": 571926,
    "start_time": "2023-12-10T12:54:13.767Z"
   },
   {
    "duration": 3,
    "start_time": "2023-12-10T13:03:45.695Z"
   },
   {
    "duration": 566295,
    "start_time": "2023-12-10T13:03:45.699Z"
   },
   {
    "duration": 4,
    "start_time": "2023-12-10T13:13:11.996Z"
   },
   {
    "duration": 24391,
    "start_time": "2023-12-10T13:13:12.002Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "188.391px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
